{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exam 2 - Luis Alberto Robles Hernandez.ipynb",
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOx3xh3DhNUaf5nlYDpc/d2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dc46ec01164b42de9eabe0cba05c7bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a2a6d1598e2b4320a395870397064c13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1e2e409fc2df45a992fe2ca14e11f288",
              "IPY_MODEL_3a411cca38ca4c50b58e687958fc4140"
            ]
          }
        },
        "a2a6d1598e2b4320a395870397064c13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e2e409fc2df45a992fe2ca14e11f288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_772c6067255142f8baa0931afd35bf2b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f0de215f792247cc8f37819484329721"
          }
        },
        "3a411cca38ca4c50b58e687958fc4140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11313b64efc6480ab2f5cf1441bc94ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:30&lt;00:00, 7.03kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20f73d74f24c49e0acad9381a725bebf"
          }
        },
        "772c6067255142f8baa0931afd35bf2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f0de215f792247cc8f37819484329721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11313b64efc6480ab2f5cf1441bc94ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20f73d74f24c49e0acad9381a725bebf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a88c142fdf724927bdb7f2d2125129c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32d90880e518476382813065877febf7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8c21831c41c84db695ce6c83141a348a",
              "IPY_MODEL_83bafd004dd84cc4a287646b81662932"
            ]
          }
        },
        "32d90880e518476382813065877febf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c21831c41c84db695ce6c83141a348a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ba79e58e5d14515a10bdf349bbd245e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b8c4d52f9114f358860e4343adc1fec"
          }
        },
        "83bafd004dd84cc4a287646b81662932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fc1a05961fae4cb0b2739b6cb6fbae4c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 128B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b2e7a499e76450f9af9360b7d99d317"
          }
        },
        "9ba79e58e5d14515a10bdf349bbd245e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b8c4d52f9114f358860e4343adc1fec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc1a05961fae4cb0b2739b6cb6fbae4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b2e7a499e76450f9af9360b7d99d317": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d1658baa9c643498b076c68d2e9b35e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c547fe6614e1421d96a46bc62bc65f93",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_76c98c9453b744ddaf7dbb31e38aa3b4",
              "IPY_MODEL_072d15ea99374a5e962138cd22c0f047"
            ]
          }
        },
        "c547fe6614e1421d96a46bc62bc65f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76c98c9453b744ddaf7dbb31e38aa3b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_64c2dcc67f1b41e19cd1a2f7923006b5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 49,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 49,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11acbe5f5f4c44b1af7563102cc17e17"
          }
        },
        "072d15ea99374a5e962138cd22c0f047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2a998a5ccb644c94b75b7eca93be5cf0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 49.0/49.0 [00:00&lt;00:00, 159B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2defb8015674912a76159d65aef8722"
          }
        },
        "64c2dcc67f1b41e19cd1a2f7923006b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11acbe5f5f4c44b1af7563102cc17e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a998a5ccb644c94b75b7eca93be5cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2defb8015674912a76159d65aef8722": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ab319fe128c4afdb2c62ee6df642b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7bd9df52aaa04d3fba8ebcaf1ef80517",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_306d7b40ae9f46318da0c79896d10e87",
              "IPY_MODEL_e914c1e231c94829842241db213b461f"
            ]
          }
        },
        "7bd9df52aaa04d3fba8ebcaf1ef80517": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "306d7b40ae9f46318da0c79896d10e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ecaf15877b6486d924dcb2f4d3f87c5",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 462,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 462,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4de593a54fac455baf7ddee563524fd6"
          }
        },
        "e914c1e231c94829842241db213b461f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4ff475e79ce4403a90e3d40d2eb1a657",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 462/462 [00:00&lt;00:00, 1.23kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2388eda3b265407d849610fd5499694e"
          }
        },
        "2ecaf15877b6486d924dcb2f4d3f87c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4de593a54fac455baf7ddee563524fd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4ff475e79ce4403a90e3d40d2eb1a657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2388eda3b265407d849610fd5499694e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "52a3320ef4f247e1a98a7d4c1773bbe6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63e4e44e449e4a248e258fe80cb52b5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_abe5d0034a6f42ab95f41f516809e6c2",
              "IPY_MODEL_3404b5a2054442bc9df9204e7bb4a658"
            ]
          }
        },
        "63e4e44e449e4a248e258fe80cb52b5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abe5d0034a6f42ab95f41f516809e6c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9ae9f80760647fca08b2335bcb8c1e8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433286112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433286112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_db4b5fccd2ef4e71a576888c99bcdcdd"
          }
        },
        "3404b5a2054442bc9df9204e7bb4a658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c069ac3e242d4883965e50035ddc61e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433M/433M [00:07&lt;00:00, 57.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_01f907ae318e47a0b6be7d133fb2c341"
          }
        },
        "b9ae9f80760647fca08b2335bcb8c1e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "db4b5fccd2ef4e71a576888c99bcdcdd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c069ac3e242d4883965e50035ddc61e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "01f907ae318e47a0b6be7d133fb2c341": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2f543aab61f46ac89e0da77159a2581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3de61feb4374689af9ccc213a7eb4db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6cb6a9f18fb14005ade333549b9d2419",
              "IPY_MODEL_554f44c227714a1ca661de337dfbaff3"
            ]
          }
        },
        "a3de61feb4374689af9ccc213a7eb4db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cb6a9f18fb14005ade333549b9d2419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_182a94c66e9b48ca841eb6795a0234c0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 313,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 313,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d18166b29ee3454f88ec891bb2e3171b"
          }
        },
        "554f44c227714a1ca661de337dfbaff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_314ec7e922224614957584e3e46ea7bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 313/313 [00:00&lt;00:00, 352B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_371141f377ab48cfb07030b8c63730f5"
          }
        },
        "182a94c66e9b48ca841eb6795a0234c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d18166b29ee3454f88ec891bb2e3171b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "314ec7e922224614957584e3e46ea7bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "371141f377ab48cfb07030b8c63730f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1936f00b399b44e0853600d40d14f349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c3d11b6fbf94d0aa8c8edc1535697e0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_469b364077e94bce9685e7189b8417ff",
              "IPY_MODEL_6164d356f9cc4c428b738cbd17ac4bb3"
            ]
          }
        },
        "7c3d11b6fbf94d0aa8c8edc1535697e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "469b364077e94bce9685e7189b8417ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40418408d720468e99feb5070b200996",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440512266,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440512266,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7c307842c959491a9f0cb52b1f04d207"
          }
        },
        "6164d356f9cc4c428b738cbd17ac4bb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e2637add551479bbc9d03a56dd2a9ba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 441M/441M [00:25&lt;00:00, 17.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e28e95c3eb54c93bd7f7f5dd5057861"
          }
        },
        "40418408d720468e99feb5070b200996": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7c307842c959491a9f0cb52b1f04d207": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e2637add551479bbc9d03a56dd2a9ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e28e95c3eb54c93bd7f7f5dd5057861": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuisRobles18/NLP/blob/main/Exam_2_Luis_Alberto_Robles_Hernandez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6U4r2IGTWXR"
      },
      "source": [
        "# **Exam 2**\n",
        "**Student ID:** 002581393 **Name:** Luis Alberto Robles Hernandez"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00-nBie0Tdxc"
      },
      "source": [
        "## **INSTRUCTIONS**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfPn2ZR8fEun"
      },
      "source": [
        "**Packages/Libraries allowed:** PyTorch, Tensorflow, HuggingFace (transformers), Keras, gensim, Spacy, Sklearn, IO, OS, Spacy, NLTK, Pandas, Numpy, Seaborn, Matplotlib, Scipy, random. IF there is a library missing here that you think you might need, please email me about it.\n",
        "\n",
        "**Styling notes:**\n",
        "\n",
        "1) Do not load any python packages/libraries inside any of the functions. You can have these in separate code cells, but not inside any given function.\n",
        "\n",
        "2) Do not print anything from within your functions, this is bad form.\n",
        "\n",
        "3) Make sure you pay attention to what the function is required to return.\n",
        "\n",
        "4) If not explicitly requested, please print out whatever the function is supposed to return.\n",
        "\n",
        "5) When printing to screen to show your results, make sure you format your output nicely and make sure it makes sense.\n",
        "\n",
        "NOTE: Set the **random seed to: 12345**. This needs to be consistently set to train the model AND split the data in test and train when appropriate. If this is not done correctly, you will lose points as your answers will not be comparable with the grading key\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqinpBOOfNaD"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "random.seed(12345)\n",
        "np.random.seed(12345)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qppHT_jJfqdR"
      },
      "source": [
        "##**EXERCISE 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HdOoYBLTgGm"
      },
      "source": [
        "**(20 points)** Write a function that takes a List of five words: [‘apple’, ‘house’, ‘pear’,‘dog’, ‘doctor’] and returns a list of lists with each element being a word and a list of the top five most similar words. For this task you have to use the most suitable method of the ones **we have seen in class** to determine the most similar words to the original input list. You can use a **pre-trained** resource if you think is appropriate. After calling your function, print the most similar words to the screen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9-Ot7KowZqO"
      },
      "source": [
        "### **Obtaining and creating the function to get similar words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9aFhPLsRQH3"
      },
      "source": [
        "#Using pre-trained Word2Vec embeddings from Google\n",
        "!gdown --id 1TeyOD9vafBT3wcF4w_vEl-IzJ5EtWOe5\n",
        "!gunzip /content/GoogleNews-vectors-negative300.bin.gz\n",
        "clear_output()\n",
        "\n",
        "#Loading the pre-trained embeddings\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "filename = '/content/GoogleNews-vectors-negative300.bin'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "wpLVkQyBqh6g",
        "outputId": "be06ce03-d753-4554-9d38-adba77ebb4b3"
      },
      "source": [
        "#Creating a function to get the top five most similar words\n",
        "\n",
        "def top_similar_words(words):\n",
        "    list_top_similar_words = []\n",
        "    for word in words:\n",
        "        data=model.most_similar(word)\n",
        "        data.sort(key=lambda x:x[1], reverse=True)\n",
        "        get_top_words = [dat[0] for dat in data]\n",
        "        get_top_five_words = get_top_words[:5]\n",
        "        list_top_similar_words.append(get_top_five_words)\n",
        "    return list_top_similar_words\n",
        "\n",
        "words = ['apple','house','pear','dog','doctor']\n",
        "result = top_similar_words(words)\n",
        "\n",
        "print(\"\\033[1m Top 5 similar words given a list \\033[0m \\n\")\n",
        "for i in range(len(words)):\n",
        "    print(\"Similar words for \\033[1m\"+words[i]+\"\\033[0m:\")\n",
        "    print(result[i])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m Top 5 similar words given a list \u001b[0m \n",
            "\n",
            "Similar words for \u001b[1mapple\u001b[0m:\n",
            "['apples', 'pear', 'fruit', 'berry', 'pears']\n",
            "Similar words for \u001b[1mhouse\u001b[0m:\n",
            "['houses', 'bungalow', 'apartment', 'bedroom', 'townhouse']\n",
            "Similar words for \u001b[1mpear\u001b[0m:\n",
            "['pears', 'apricot', 'apricots', 'nectarine', 'Fuji_apple']\n",
            "Similar words for \u001b[1mdog\u001b[0m:\n",
            "['dogs', 'puppy', 'pit_bull', 'pooch', 'cat']\n",
            "Similar words for \u001b[1mdoctor\u001b[0m:\n",
            "['physician', 'doctors', 'gynecologist', 'surgeon', 'dentist']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gf-vCqzf8ZM"
      },
      "source": [
        "###**Answer the following questions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vamFSXyJf_7z"
      },
      "source": [
        "**Are these ‘similar’ words actually similar? If not, why not?** Analyzing each of the \"similar\" words from each word, all of them have a similarity but in a different level. For example, the word \"dog\" is similar with \"dogs\" because the only difference is that one is singular and one is in plural form. The word \"puppy\" is related because that's how the \"baby dogs\" are usually called. \"Pitbull\" is a type is dog. \"Pooch\" is a slang term for \"dog\". And the last one, \"cat\", one thing that have in common is that both \"dog\" and \"cat\" can be pets.\n",
        "\n",
        "As we seen in the previous example, all the words have something similar, although the level of similarity starts to decrease as we progress through the list.\n",
        "\n",
        "**What do you think can be improved and how - talk about it, do not necessarily implement it?** In this exercise, the smallest available pre-computed embeddings from Google was used. This means this task it can still be improved if using a larger pre-trained Word2Vec embedding, although this would require more CPU resources. This is one of the challenges that computers faces as time progresses, because data from the internet grows at an exponential rate while CPU resources doesn't. For this exercise, using the largest data could not be the answer because it can also lead to ambiguity, but at least, using a larger pre-trained Word2Vec embedding compared to the one used in this exercise, can improve the results when searching similar words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD1zt5CcsZF6"
      },
      "source": [
        "## **EXERCISE 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my3yjhlTsbDe"
      },
      "source": [
        "**(30 points)** Using the Homework 2 dataset, also attached in the Exam 2 files,\n",
        "shakespeares-works_TXT_FolgerShakespeare.zip. Find the document to document similarityusing:\n",
        "\n",
        "*   Cosine similarity. And create a 42 x 42 heatmap of these similarities.\n",
        "*   Use Doc2Vec to create document embeddings and find the similarities between the documents. To visualize this, also create a 42 x 42 heatmap for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQ4sGIxatB3U"
      },
      "source": [
        "#Downloading the Shakespeare's work to the root folder\n",
        "!wget https://github.com/LuisRobles18/NLP/blob/main/shakespeares-works_TXT_FolgerShakespeare.zip?raw=true -O shakespeares-works_TXT_FolgerShakespeare.zip\n",
        "clear_output()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlHPY3ZFuEyZ"
      },
      "source": [
        "###**Cosine similarity - Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "fb3blySitQQC",
        "outputId": "1171f218-76e0-464a-833b-e3389c56303f"
      },
      "source": [
        "import zipfile\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "#Obtaining the ZIP file\n",
        "my_zip = zipfile.ZipFile('shakespeares-works_TXT_FolgerShakespeare.zip')\n",
        "storage_path = '.'\n",
        "#Each txt file inside the ZIP file will be stored in a list\n",
        "documents = []\n",
        "for file in my_zip.namelist():\n",
        "    #Only TXT files will be accepted to be stored in the documents and documents name lists\n",
        "    #For some reason MAC OS's generates an extra folder called \"__MACOSX\" which will be excluded\n",
        "    if my_zip.getinfo(file).filename.endswith('.txt') and not my_zip.getinfo(file).filename.startswith('__MACOSX'):\n",
        "        my_zip.extract(file, storage_path)\n",
        "        with open (my_zip.getinfo(file).filename, \"r\") as doc:\n",
        "            documents.append(doc.read())\n",
        "\n",
        "#We call the TF-IDF from the Sklearn module\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "#We generate the tf-idf vectors for the text files\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n",
        "\n",
        "#Computing the cosine similarity matrix\n",
        "cosine_sim_matrix = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "#We reshape to a 42 by 42 matrix in a numpy array\n",
        "a = np.array(cosine_sim_matrix)\n",
        "new_cos_similarity_matrix = a.reshape(len(cosine_sim_matrix),len(cosine_sim_matrix))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(new_cos_similarity_matrix, cmap='hot', interpolation='nearest')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb377920a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAEvCAYAAAAtufaDAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2de5RddZXnv5syL0IK8ioqVCIFAUmHIAUU4RFoIxqMDJr4aGl6ZGBE0+0yq7FRR6C1oVFXI6Mga8ZFd3hIGJSHPOQxtBBeHRAaqEAIyBuswZQJBemE8JIkxZ4/zqmmIL/vrlu36t7yR76ftbJStX+1z+93f+fcfc89+2XuDiGEyJXthnsBQggxGGTEhBBZIyMmhMgaGTEhRNbIiAkhskZGTAiRNR8YjLKZzQdwHoAGABe6+1nR30+aNMlbW1u3Hli1IpiEyIPIkJ7NafnbXAUjRqfl6/7IdSaStW2uImol+jRpIGujewMAbxH5KK7S82ZaTsQA+Lq3Z2sGALan7GoMjvXKa2l5QzA925oxgU5PFTovEfmU7bnOq2+k5eOCF/QKWdyOI7jOFvIeCS537LBDWr6JnAMAWB0cjzGByJ8DXnb3ye+VV23EzKwBwE8BzEOx1gfN7AZ3f5zptLa2oqOjY+uBluDdyE4Eu6oAbCQ7R64PAEDzHmn50se4zvFk97rIBRIxLhhr3I0MRIbiGSLfk6tsfDgtfySYhr0fD2BrBtDzRFresBNRmMmPdfPytHxHroLnBz4NXiHyfQOdfyHy02ZxnbseSMvnBi/oxv9Iyz+1M9fpJu+Rp7gKDm9Ly1+4h+t8i8ijG4pjifxzwP9LyQfzdXI2gGfd/Xl33wTgCgALBnE8IYQYMIMxYi0Aft/n99Wl7F2Y2SIz6zCzjpdeYjfYQghRHTV/sO/uS9y93d3bJ0/e6uusEEIMisEYsS4A0/r8PrWUCSFE3bBqE8DN7AMAngbwMRTG60EAf+Xuv2U67SPNO1I3Y13BGi4gD/2/sgvXee0Pafl/4yp07LhAZzGRJx8/ljD3D3PJAMAiIn810GFEN8M/JfJrA52JRH5poHM1kbO1fTk41p8ReeDAoE6P6Cn9vUT+Wa7yW7IHe0fXx1winxHoPErkqwKdM4icnRsA+L9Efh5X+dUlaXljMM1HiPwDwAp3b0/Iq8Pdt5jZYgC3oPBoXxwZMCGEqAWDihNz95sB3DxEaxFCiAGjiH0hRNbIiAkhskZGTAiRNTJiQoisGdSD/QFjSOdCsjAKAPgKCb+4JtC5k8ijXEMWrhDlQUZZxgMlmodEjITJoCxiL3LVszzVaN9Y8iRbM8D962w/o2MxgtxautfROWBrDpK56bb9ng0Ea2B5pQDft+sCnXVEHrwemtEe7BtLtt8QTNPA1kCud92JCSGyRkZMCJE1MmJCiKyRERNCZI2MmBAia+rrnXSkvUZRMjfzQn4uSBo/guiczFWwVVppSXOgw6ptTg10mBeUJVIDwCcGeCyAe4xaRnKduzel5VHNYuYZOyrQYQnYrLxtlMzNvHbBJUX3ZhqRAzzJOthO6ryeE6Q/77IxWASB7cGXgqoCL5FysPcH8xxE5Mu4Csvpj94ioZc4ge7EhBBZIyMmhMgaGTEhRNbIiAkhskZGTAiRNTJiQoisqWuIRc/mdGPbRlYTH+DJ3CyMAgDGk/CLhwOdRE9fAFgb1ENvZmuLsltZ0nZU+/42Io864LF68RtIGAUA3JcWv/AyV5lGxuwWrgPWbHUskQd78zrp9jo2CAvpIee0IThv68jrnMhq7wNYSeStNwZhFKSBcZQEv4k0wh0Zvb1JR+T1z3KV8f9GBoLmuQ8SeZSf/7ZCLIQQ2xIyYkKIrJERE0JkjYyYECJrZMSEEFlTV+/k20g75xqjztysxm+UzM28kCuDpPFvpnXWBtM0M+9gZ6DEsoIj7yTzCrESwwBwPZHvFegQ71yQ40xzw8dE3UjZvjHPLUsYB3cEjw68yqw69K6BZ446OwMvKHO24m6u00U8cy1BKXKSyo3mL3ZzJeI6ZeWkAXAvebDXrEYBcY4CiN8KKQZlxMysE8U6ewBsSbUYF0KIWjIUd2IfdfcgkkgIIWqHnokJIbJmsEbMAdxqZivMbFHqD8xskZl1mFlH9AhHCCGqYbBfJw9z9y4zawKwzMyedPflff/A3ZcAWAIA+5oFT9aFEGLgDOpOzN27yv+7UbTqnD0UixJCiEqp+k7MzMYC2M7dXy1/PhLAmZHOiNFA8x6JgSjEgvloIz8oSeZmYRQAgB+lbxLbfhboHE3kUU16NtYa6Jz0o7R8+Te5DkuijerVk/CP5ijOZHci/2qgwxLnGR/nQy3nk4Gg03krS6YOCr+3PE4GDuU6+zxGBs7mDQBaHiaLY93ZEZyfU7kOC9tp/qdA53NE/jpX2eeitPyYnYN5BtgJfjBfJ3cGcJ2Z9R7nF+7+60EcTwghBkzVRszdnwcv+CKEEHVBIRZCiKyRERNCZI2MmBAia8y9fqFbu5n5GQn58TsESszLFnTmZiWlIydbG2uWvI7vz1pLey5ZgjHA89lHBTof2pUMRF5QlhUcdMZ+juwbyz8HALZtCwPv0/oX03LWyNqCJ6+/IpnE7FgA8DyRM0crwHPQo0bnxKeMcw/hOleSEuHR2tjrOWYS11lPEgVvDeY5Zre0/OnfcZ1vBMdjfJQfa0UqP1t3YkKIrJERE0JkjYyYECJrZMSEEFkjIyaEyBoZMSFE1tQ1xKJ9O/OOVKJT5IdlyaA7BjoswTjqmE2SudeewVWa2d5F3clZsuxErhIlQFNY3fMoUexyIq8mxiI6pyxBnx3riOBYXyLyaVzlzSfS8jGp4gQlPaT+fsORXOc3JF5hzqVcBycQeVDwwB9Iy+17wTzLiDwqfn8Okf+Mq1xAuoPT/gPgl/vOCrEQQrwfkRETQmSNjJgQImtkxIQQWSMjJoTImrp2AN/s6Q7HLUEHYUpQSpi2he4MdEgydZTM3cy8kHcEHt9WohO1XmbdnyNvK8t2jzKJu4iYJeEDmECSucewBHSAbyorRR5k7ne9lpZPJh5IgG/bB4N52JJbg2uXJWbPCS6q7rfT8qZgHnIK4rLiZA3rX+Eq49kLYnIAq4l8FleJGoon0Z2YECJrZMSEEFkjIyaEyBoZMSFE1siICSGyRkZMCJE1/YZYmNnFKNKju919VimbAOBKFH2rOwF8wd3XV72KqFY8g7njAR6SwJLJgzWwmvgAeDI3C6MAgE4SfjEj0GH7s4mrUJ3I7U50egIVEhHAa/z3d8AUUShJFdCIkSDMZaBLBoLLjV2fEUP9HiEE0TRhp28G27codCnI3U9SyZ3YJQDmv0d2CoDb3X1PALeXvwshRN3p14i5+3Js/bm6AMDS8uelABYO8bqEEKIiqn0mtrO7ryl/XguANugys0Vm1mFmHeuqnEwIIRiDfrDvRVVFmmfj7kvcvd3d26O6f0IIUQ3VGrEXzWwKAJT/dw/dkoQQonKqTQC/AcDxAM4q/7++EqXtAIxLDbCyxAB3l0S3dZMHKAcKP2uCqDM3XUOUzM28kE8GSePnBJ5LBtu3aA9I2+yolPDYEWQg6ABOD8g+UpMXTTw0MugqP44kjWN7rjOBJUaz149g2UEZbHpZBydhFFtbdA7a0uLRQTdvurjg/DDvflSHIDIHKfq9EzOzywHcB2AvM1ttZieiMF7zzOwZFCWxzxrgvEIIMST0eyfm7seSoY8N8VqEEGLAKGJfCJE1MmJCiKyRERNCZI2MmBAia+paY79hNNC4W2JgUaD0ByL/RKBzG5FHnaxP+lFS/KFzv8l1WKviKMGXJfJGYRQnk/CLFYEOc/1H2bVkbROjoud7EfnfBjqtRM6yhRfwQzWybtpsXQCa2DXVynXGs2vnk1znoMfIwAnzqE7DVaQ1dxDGMJ5lU/8d12HvkcaVgc6niZz1tABw0FNp+bxJwTwsc540E9CdmBAia2TEhBBZIyMmhMgaGTEhRNbIiAkhsqau3kkY0hmh1ZSajnRYOeOooNly4oWspixwVE45KinNYF7IA4Kk8buIzp7BPKyV9BcCHeaBi84PK5HNPHBhzWRCdN6YNy06N+zjPkj2Z1vQ1EU8kADfmyA5nb6eqET440QeZft/+Ltp+evfoyrM0fj0y3ya6cESUuhOTAiRNTJiQoiskRETQmSNjJgQImtkxIQQWSMjJoTImvqGWLwF4JkB6nQReeR235fIo04A7HiRm5olRlfRZTt8PSyZm4VRAMBcEn6xKdBhIShXcRVMJXLaGhw8lIPtTZBgTAsEBAnT9JyydUXzsOszmGZ61EmbhedEoQ9sor2DSvZvPJ+WR625/52HUjDYqduxCh2G7sSEEFkjIyaEyBoZMSFE1siICSGyRkZMCJE1/XonzexiAEcD6Hb3WaXsDABfwTu+lNPc/eZ+ZxuFdAJy1JV6BpG3jOQ6G0gmb1CymCZG7xLoMC9o1N6YeS6jPWAlpaNkbuaFHBkkjbPu5O3BPKRrOKYHfZz3IO60ZvL3ezfxY83sTsuj7tesLfXMQId5bvfnKrtcQwbYngF8D6K1sbLekZ+PXdfRtXswOac3cRc+m4a9rQFgLLu1Ih7vSu7ELgEwPyE/193byn/9GzAhhKgB/Roxd1+OOFpKCCGGjcE8E1tsZqvM7GIzG8/+yMwWmVmHmXW8tGUQswkhRIJqjdj5KGqXtQFYA+DH7A/dfYm7t7t7++T65gcIIbYBqjJi7v6iu/e4+9sALgAwe2iXJYQQlVGVETOzKX1+/Qx4kWIhhKgplYRYXA5gLoBJZrYawOkA5ppZGwAH0AngryuZrOdNYOPDW8sbfxooseTnu4OC6PcReZRZSoqBPxd0v55+ORkIkoJpknPkdmc6UcIyCwlgYRQA8J10+MX673Idtmw7NfAFPTLAg20gYRQAuu9Jy5tG8enXkrr4zQ9xnXWvpOUTb+I6DxJ5yxKus74jLR8f9CzYSLpsNy4OzgHZt43s3ABo/D453rVchzVOv5er4OioeECCfo2Yux+bEF80sGmEEKI2KGJfCJE1MmJCiKyRERNCZI2MmBAia+oafvom0o6pwwPvBk3WDTo8v0C6Cwcp42gmidnMuwIA08lgV1BqmuXqRtWHJzIPadSZm5WUDpK5mRdyvPOk8RWW1jngaj6PP5uWG8sZDzq3E2cedgw6c5PCzJhBPJAAP28jmCccPO5o4YVchx2unXggAeB+Iv8U854DeIE4GiOH94GkFPnaJ7gOW3ZnMA+rd8DQnZgQImtkxIQQWSMjJoTIGhkxIUTWyIgJIbJGRkwIkTV1DbHYDsD2qYGJgVJSATRhGwCmkRCLICqD1hafQI5VDBJx4Kdmua1jWaI7wHsDRLVDWGfuINGcDbEwCgA4gIVfHMR1bBIZYF27gzWzqIwon55FUgRdAWhj7sbgvG3PQm2CMJcdSThNU3C7MY5dVEGsQjMJsQhLOJOwnaibN9ueqMZ+1Lw9he7EhBBZIyMmhMgaGTEhRNbIiAkhskZGTAiRNeZBcu9Q0z7GvGO3xMAlgdIfiPyoQOcWIo9a/H6VyI8MdL5B5JGLh41FHav/lsiDksXUDRp15mYlpYNkburSuz+4rv4n8Vwyl2KqtnAvhxB51O2dJKBjVqBzG5EHa+v8SVreGiSn43Ainx7oPE7ktwY6LAn9skDnN0R+Jle5i+xB1Ly+hbg0bTNWuPtWvl3diQkhskZGTAiRNTJiQoiskRETQmSNjJgQImtkxIQQWVNJB/BpAC5FEQTgAJa4+3lmNgHAlQBaUZTM/oK7rw8P9kegJ1GPuyFy4TcS+TOBDuluTLN4AeDOtHh9kMw9nhV4/30wTzVF9luJnPQFAMCLpe8x8M7crCY+ECRzszAKAPgWCb9YPMDQC4CHFwTd3t9cnZaP2ch1esh+NgTXYSeRt0bXO7umgoIHeJLIzw90WGH+4Fzj0gEeC7zZO2sbAQBHBz0qUlRyJ7YFwDfcfSaAgwF8zcxmAjgFwO3uvieA28vfhRCirvRrxNx9jbs/VP78KoAnALQAWABgaflnSwEsrNUihRCCMaBnYmbWCmA/FDeQO7v7mnJoLUjMuZktMrMOM+uIvs0JIUQ1VGzEzGwHANcA+Lq7v+vpgRe5S8kHHe6+xN3b3b198qCWKoQQW1ORETOzESgM2M/dvbfV7YtmNqUcnwKguzZLFEIITiXeSQNwEYAn3P2cPkM3ADgewFnl/9dXMltDytMU3aIxr0xUw5Z5+t4IdAiRY4wmP0eJ2Yzo44R5NKM9YLW4mwMd8mJpZ+5oDdHGMS/k/yZey98Enk7WIT4oG81UojLpDawQQeBVplsQnWu2uGg/mU50fTAPYFSIgI0F71+2hNeDaQZanrqSGvtzABwH4FEzW1nKTkNhvK4ysxNReEy/MMC5hRBi0PRrxNz9HgDso/BjQ7scIYQYGIrYF0JkjYyYECJrZMSEEFlT1+a5GA1gZkL+5UCHeYWi+rbMWxLlW348LbZ9A50jiDzKaWQRv5FLZgGRRzlmLHdw76ZAh0TJrAvmqaakNNNhXsg5Qalr1qQ3aBxrrWQgaGpLz88nuMpepNksLUENAOx6OzTQYdfBycE9ymZSvzy6rTmGyINc4X1vSMujVOGRu5IBknCpOzEhRNbIiAkhskZGTAiRNTJiQoiskRETQmSNjJgQImvq2gF8TzM/LyE/Kko6ZQQJsa8/lZYHFYvRkupMDuBXv+M6C3dIy7teCyYiRBEWjVFnagYLTUmFuJR0k7LerGIywHPgD47WzEpKs0Tmg4Jj3ZG+fh80njTeReRRk+3niHzhHlzndFLq+R9nc52bH0jLo+384GFkgL1QgIYr/Jp1jgcwn6y7i6wZAE4m8ijEgp3uv4E6gAsh3ofIiAkhskZGTAiRNTJiQoiskRETQmRNXRPAGwDsmBqIkrlZaeZduMpYUpp5dNSxc0ZavFPgnWRJxpMTDYL7YyTxdAIA9iJyVoIa4O7OwBPcNCot3/EtrkOdxGzNAHcTs5LSQTI380IeGHjdNxGdqEo67asbXFO0qneQAD6NePqi6tQriFf5gE8GSq+kxTOC3srsPLQ8zFUmk+T0yBsfONCT6E5MCJE1MmJCiKyRERNCZI2MmBAia2TEhBBZIyMmhMiaSjqATwNwKQrnvANY4u7nmdkZAL6Cd6rGn+buN0fHegvA8wn5nKj2PasfHtSX7yFu76AUOFpJwnRqvb0cREIpWBl9gC97XJA03sSSuaOMduYqp+2vgbUklCLaA+KpxwyS/AwAb65Oy9nSrJUfi+U4szAKAJhDwi9WBDosZ31mcB12soG7uQ5LNN/EVWiu/wF0AUA3uT7uD+ZpJRdCZ7AHLAIlSmi/NxhLUUmc2BYA33D3h8xsHIAVZrasHDvX3X80wDmFEGLIqKQD+BoAa8qfXzWzJwC01HphQghRCQN6JmZmrQD2wzt3nYvNbJWZXWxm44nOIjPrMLOOVwe1VCGE2JqKjZiZ7QDgGgBfd/eNAM5HUUeuDcWd2o9Teu6+xN3b3b09SjUQQohqqMiImdkIFAbs5+5+LQC4+4vu3uPubwO4AEBQr1IIIWpDJd5JA3ARgCfc/Zw+8inl8zIA+AyAx/o71hiQ5M6oyzbzfARJwQ3Ea7dr4DHD1LR490e4yhhSmviDUQdwlky9faDTSuSRy+pFIg+ya5sfSstnMBckgiTnwP00hmVTTyTyoDP39DvT8iiZm3khDwiSxv9IdMYnKxoU7Mn2LTgHrSQBfB+uggY2QIoaAEATcdXPikqrk/dpK3PdAtidXO9ReeqBJoBX4p2cA+A4AI+a2cpSdhqAY82sDUXYRSeAvx7g3EIIMWgq8U7eAyD1MRTGhAkhRD1QxL4QImtkxIQQWSMjJoTIGhkxIUTW1LXGfg9IwnCU8dlI5I9ylXUvp+VRSfoW4iaOctMPJyEbUaI5axkwIQhjGP9vZCD6CGJZweu4yjqyBrZmgCe7T7+N6/SQ8I8GtuYgSpolTNOa+ODJ3CyMAuBJ42sDHZqfH4TtsP2MonbYNdrGrhsA60goBYvMAYC9SSv4zqAHA3svRO8r1dgXQmxTyIgJIbJGRkwIkTUyYkKIrJERE0JkTV29k2NAckg/GyixxOiRXGUi83ZG7slD0+KjlnCVhiPT8tao0ziDdb8GANbJOfAK0brN+3OViTel5SPu4zqNbN3Hcp0G5ppiWcGf4MdayNxfwTlgJaWjZG7mhWwOksZnMM/lR/g8M0k37ZY/4zoLWMf5z3OdiU+m5e3LuQ47p62XcZV9ydqiBPBdg7EUuhMTQmSNjJgQImtkxIQQWSMjJoTIGhkxIUTWyIgJIbLGPHARDzUtZv61hHxBoMO6QtO64gBWEnnk1mU1zH8Y6DAPdtQxm6076gR1EJFHLfBYA/BdAp0HiTxqnsAiYKKomU4i34nI9wqOdRaR09r/wfx7BjosmTsoY4/PkvdW1J38bCKP9oCdnyDKBSTCAk8FOv+dyIM8c/yAyIOm4TiayM8GVrj7Vh0XdCcmhMgaGTEhRNbIiAkhskZGTAiRNTJiQois6dc7aWajASwHMApFwvjV7n66me0G4AoUfZtXADjO3aOe1Ggfa96R6gz9y0CJJfjOYXWrAdxIihPfHcxzNvHbHcpqJgP4KpFH9anfIHLSTRwAcMK8tLxrGdd5nciZCxAAWLL7hYEO6879i0DnaiJnH6mHB8dibtBIh10HUV1kVlI6SObe9JO0fGT0nvsy91xSWEL9FYEO6ZyOpYHOPxP5VVxl5SlpedjR/JC03O6r3jv5FoAj3H1fAG0A5pvZwSiiD8519z0ArAdwYgXHEkKIIaVfI+YFvW0FRpT/HMAReOczdSmAhTVZoRBCBFT0TMzMGsxsJYBuAMtQNJnZ4O5byj9ZDaCF6C4ysw4z63hpS+ovhBCieioyYu7e4+5tAKYCmI04UPm9ukvcvd3d2yfXtQSjEGJbYEDeSXffgOKR4CEAdjKzXrM0FbyWqBBC1Ix+jZiZTTazncqfxwCYB+AJFMasN33weADX12qRQgjBqCTE4sMoHtw3oDB6V7n7mWa2Owon7gQADwP4ortHVd+xl5n/S0I+d7dAiWWKRpnMpE55V5B12vLxtPzKoJP1MeQjoPttrsOYGIw1sBr7UVto1kq6mausJx2egxL7YGXp58wOlMg8NNs/2Zih4GayuGnB9KxreGugw7Yzisr4GZF/J/LjX5h+P74ZJI2zBOz5QV3+HlL7PopCmkvOafcDXOfrRL5zMA+LWvkMSQDv9ymVu68CsF9C/jyK52NCCDFsKGJfCJE1MmJCiKyRERNCZI2MmBAia+oafjquAZibcmdFobNRwjKD5Gy3sORrgHbg3j2ahyQ/N0UdwFkX8qh2NqtdzWpDR8cL3GnjSb3r9qBmcRP7GJzOdWiNbnauSXd2AJhFvJPRZcOqFERJycwRHHXm3ot15g5gXsgxQRRBG/NcBu+rBvIe2ecVroMD0+Loem9/MS2PaiRUHElfojsxIUTWyIgJIbJGRkwIkTUyYkKIrJERE0JkjYyYECJr6hpi8UoPcGOiNfWnHg2UBuqOB7BpdVrOumIDQDPxoUfdvNtJ4ivxKoeMClzb45k/mrWlBviL7eEqG0koxf3BNONIsvvcxwMl1n6aJYAHifsfPCwtX3EP12FdE6Ku8qyM/YIgjIJ15v4LdjDwZG4aRgGgmYVfzOA6G8n1xrrAA8B8MtgdXPDs2okiiu4NxlLoTkwIkTUyYkKIrJERE0JkjYyYECJrZMSEEFnTb3nqoaR9pHlHqi7tqkDpOiL/0oRAiThdv9jNVU4l8rnBNCcReVQ2miRZh/V6/47II3fr3ix1PXBpLiYHvDyYh9WBvjXQOZ/IWaL7ycFn7e7EPRplEXcSeaTD3IafJ3IAT5KO6jOCpvL4GJFHa2Oe4CeD9/b3iecyVT++l98QOavDDeDGM9Ly/YNpJhP5KFKeWndiQoiskRETQmSNjJgQImtkxIQQWSMjJoTIGhkxIUTW9JsAbmajASwHMKr8+6vd/XQzuwRFs97eVNIT3H1ldKwtm4HuRHJ20xmB0joifymIL3iEyKPVERf6+pe5yvhlZCAqIM5oC8ZYF/IoyfoNkroedU4nSdMvBFvdTMZGXhjMw7KCWaL35qClOqvvHiTUd5M1NwXnbd1raflElswOnuc+406uwzpzs5r4AE/mbmRhFADwnXT4Rfd3uU4TC6W4kk/zEJFH7S5mBWMpKqli8RaAI9z9NTMbAeAeM/vXcuxb7n71AOcUQogho18j5kU0bO/n0IjyX/0iZIUQIqCiZ2Jm1mBmKwF0A1jm7r1fCH5gZqvM7FwzG0V0F5lZh5l1sG+GQghRLRUZMXfvcfc2AFMBzDazWSgSdWag6EY3AcC3ie4Sd2939/aJQ7RoIYToZUDeSXffAOBOAPPdfY0XvIUie2p2LRYohBARlXgnJwPY7O4bzGwMgHkAfmhmU9x9jZkZgIXg1Xj/kz8CSFVAbopcA6zLdVAzef2zaflbwTTN/5SWR3nMxxAv6PrAM8YccKN/x3UamVc1qvHLPG1BS/ON5PVE5baZ47LtskCJnB+aBB981P6a5X8HHlV26cwiHkiA70H7cq5DG6cv5Tp3E3nUmZuVlJ4fJHMzL2RTVBDi8LTOxqBEN7sMmdcSABYHYykq8U5OAbDUzBpQXE5XuftNZnZHaeAMRfDC3wxwbiGEGDSVeCdXAdgvIT+iJisSQogBoIh9IUTWyIgJIbJGRkwIkTUyYkKIrKlvjf1x5h2pROf/FSi9ROQHBTqsHjpLpAaAzxH5CYHOd4g8ahv+OpFHkcCfJvIPf5fr/Pv30vKDg94E3ydxCVO5Cq4i8p8HOpcSOQuxOCY41sFEzmr/A/z87BvodBD5sVyl++/T8qbo+vhLIj8w0GExFr8MdFgyd/QeuZvYin/gSePsMmTtFABg7x3ScntNNfaFEO9DZMSEEFkjIyaEyBoZMSFE1siICSGyppLcySFj02vAC4kSyB88L1BiGdOsNDRAyyzTUsYA9Ro+HSRmf4h5eCLvEyNy17Cm3a8T10/ETUFm9LVp8dogwXW5fKkAAAc8SURBVHdHIh9zZrAGloHNWj8HZaO7HkjLWx7mOp3kmmoNyn13kuoBrUGiO3OS/wXz6ALoJq+nKbh2u0l2Oi0nDdCS0lEydyPzQp7JIxxu+V5aZzSfBpuDRPwUuhMTQmSNjJgQImtkxIQQWSMjJoTIGhkxIUTWyIgJIbKmrgngE8x8XkIe5NDSuvjMGw/wfNhXA519iDwqFc/yshNNzv+THiKPXM4s170h0GFRGVEDcBYSQGvFo2hCmiI6p6xBO4syifKyzyby6Ppg0QpB+wEa5RGt7ToivyTQYa9nq6znPrCIlS8GOqzGfdS8/stEfkugczqxL2ONJ40fRuS3QgngQoj3ITJiQoiskRETQmSNjJgQImtkxIQQWVNxAnjZPLcDQJe7H21muwG4AkVh5RUAjnP3Tf0dJ9WwuTH4e+ZliyomMw8g84oBwDGkNPJlQftr1oB7VjBPFY25MW9SWv70y1yHJWbPCOa5l8g7Ax12vD0DHeYdZJW7o0bnbCzKp2fnJ5rnmSp0WO0C5gkHeIXuyGvI1rB/oPMGkUedudmeRp515oV8PYiKODTwXKYYyJ3YSQD65rj/EMC57r4HgPUAThzQzEIIMQRUZMTMbCqA/wLgwvJ3A3AEgKvLP1kKYGEtFiiEEBGV3on9BMD/wDvfBicC2ODuW8rfVwNoSSma2SIz6zCzDha4KoQQ1dKvETOzowF0u/uKaiZw9yXu3u7u7aOqOYAQQgRU8mB/DoBPm9lRKJ7hNQI4D8BOZvaB8m5sKoCu2i1TCCHS9Hsn5u6nuvtUd29F0drzDnf/rwDuBPD58s+OB3B9zVYphBCEwdTY/zaAK8zs+wAeBnBRfwoTkE4M/kig07A9GWD+awBvk7EoKZhlU380UPk4kUel/Flj6qAvN13b9ECFhaaMDT62jk7FvyBups3c7i0sMxzA0eT8sGON3JUf6yCy2TO5Cg0liXTYWLA02ry+4RCu85H70vJqQmOi652FmSwOdFhn7qgm/h1EHoVR3EvCL4zoDMiIuftdAO4qf34ewOyB6AshxFCjiH0hRNbIiAkhskZGTAiRNTJiQoisqWt5ajN7Ce847yYBCFKY68Jwr2Fbn/9PYQ3b+vx/CmuodP5d3X0rp2tdjdi7JjbrSNXL3pbWsK3P/6ewhm19/j+FNQx2fn2dFEJkjYyYECJrhtOILRnGuXsZ7jVs6/MDw7+GbX1+YPjXMKj5h+2ZmBBCDAX6OimEyBoZMSFE1gyLETOz+Wb2lJk9a2anDMP8nWb2qJmtNLOOOs15sZl1m9ljfWQTzGyZmT1T/j++zvOfYWZd5T6sLGvG1Wr+aWZ2p5k9bma/NbOTSnld9iCYv557MNrMHjCzR8o1/GMp383M7i/fD1ea2cg6z3+Jmf2uzx601WL+PutoMLOHzeym8vfBvX53r+s/FIVlnkPR4GckiiZEM+u8hk4Ak+o855+jaEDzWB/Z2QBOKX8+BcAP6zz/GQC+WafXPwXA/uXP4wA8jaLCTV32IJi/nntgAHYofx4B4H4ABwO4CsBflvJ/BvDVOs9/CYDP12MPyrlPBvALADeVvw/q9Q/HndhsAM+6+/NetHi7AsCCYVhHXXH35QD+4z3iBSiarAA1brZC5q8b7r7G3R8qf34VReesFtRpD4L564YX9FbfGlH+c9Sp6U4wf92oRdOh4TBiLXh3Gz3aZKSGOIBbzWyFmS2q89x92dnd15Q/rwVvO1hLFpvZqvLrZs2+zvbFzFoB7IfiTqDue/Ce+YE67kH5VWolgG4Ay1B8K6mo6U4t5nf33j34QbkH55pZLdthVN10iLGtPtg/zN33B/BJAF8zsz8f7gV5cS9d73iX81EUiG0DsAbAj2s9oZntAOAaAF939419x+qxB4n567oH7t7j7m0o+lLMRly0tebzm9ksAKeW6zgQRZHhb9di7sE2HWIMhxHrwrsrHte9yYi7d5X/dwO4DsNXofZFM5sCAOX/3fWc3N1fLC/qtwFcgBrvg5mNQGFAfu7u15biuu1Bav5670Ev7r4BRZ+KQ1A23SmH6vJ+6DP//PKrtrv7WwB+htrtQW/ToU4Uj5GOQJ+mQ+XfDPj1D4cRexDAnqVHYiSK5iM31GtyMxtrZuN6fwZwJIDHYq2acQOKJivAMDRb6TUeJZ9BDfehfPZxEYAn3P2cPkN12QM2f533YLKZ7VT+PAbAPBTP5urSdIfM/2SfDxFD8TyqJnvgtWo6VC+PxHu8E0eh8A49B+Dv6zz37ig8oo8A+G295gdwOYqvK5tRfO8/EcXzgNsBPAPgNgAT6jz//wHwKIBVKIzJlBrOfxiKr4qrAKws/x1Vrz0I5q/nHnwYRVOdVSgMxT/0uSYfAPAsgF8CGFXn+e8o9+AxAJeh9GDW8h+AuXjHOzmo16+0IyFE1myrD/aFEO8TZMSEEFkjIyaEyBoZMSFE1siICSGyRkZMCJE1MmJCiKz5/50GbBUDdaDMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtMVzYAVyAKA"
      },
      "source": [
        "###**Doc2Vec - Heatmap**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "pubUSgRIyEsd",
        "outputId": "9d14576e-a177-4825-c092-a7dfe83babf9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "\n",
        "#Sentence tokenization and word tokenization process\n",
        "full_play = \"\".join(documents) #All the files will be joined together and stored in a variable\n",
        "sentences = sent_tokenize(full_play)\n",
        "corpus = []\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "    corpus.append(word_tokenize(sentences[i]))\n",
        "\n",
        "#Labeling and training the model\n",
        "labeled_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
        "model= gensim.models.Doc2Vec(labeled_documents, min_count=1,workers=1, window=10, epochs = 5)\n",
        "\n",
        "#Sentence and word tokenization per document\n",
        "document_tokenized = []\n",
        "\n",
        "for i in range(len(documents)):\n",
        "    sentences = sent_tokenize(documents[i])\n",
        "    for j in range(len(sentences)):\n",
        "        document_tokenized.append(word_tokenize(sentences[j]))\n",
        "\n",
        "#Initializing the matrix\n",
        "sim_matrix_2 = []\n",
        "#Computing the similarity matrix\n",
        "for i in range(len(documents)):\n",
        "    sim_matrix_row = []\n",
        "    for j in range(len(documents)):\n",
        "        sim_matrix_row.append(model.n_similarity(document_tokenized[i],document_tokenized[j]))\n",
        "    sim_matrix_2.append(sim_matrix_row)\n",
        "\n",
        "#We reshape to a 42 by 42 matrix in a numpy array\n",
        "a = np.array(sim_matrix_2)\n",
        "new_cos_similarity_matrix = a.reshape(len(sim_matrix_2),len(sim_matrix_2))\n",
        "\n",
        "clear_output()\n",
        "#Plotting the similarity matrix in a heatmap\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.imshow(new_cos_similarity_matrix, cmap='hot', interpolation='nearest')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fb35ee50fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRt4e7NnsmTe"
      },
      "source": [
        "###**Answer the following questions**\n",
        "\n",
        "**What are the differences you find between the two methods?** The similarity results on the Doc2Vec approach are relatively higher compared to the cosine similarity approach.\n",
        "\n",
        "**Is there anything radically different? Please describe your answer in terms of the heatmap of part a and part b.** Yes, looking at the heatmap from part A and part B we see that the similarity between each document is higher in the Word2Vec approach than the cosine similarity approach. The only thing similar we see is that their same documents are 100% similar (see white diagonal line in both heatmaps), but the rest is completely different. Cosine similarity computes similarity between samples while Doc2Vec is an NLP tool for representing documents as a vector. I think the reason why they are different is because of the parameters used to train the Doc2Vec model, specially with the window parameter, in which specifies the maximum distance between the current and predicted word within a sentence. I think that, increasing this number we could get a more reliable result and see if it gets closer or not from the result from the cosine similarity approach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP_Fog-l_bJ-"
      },
      "source": [
        "##**EXERCISE 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsTYeoMl_d9K"
      },
      "source": [
        "**(30 points)** Using the Homework 2 dataset. Use SpaCy to extract the following:\n",
        "\n",
        "*   Write a function to generate all **unique bigrams** from all documents in the dataset. The input of this function should be the concatenated dataset and the output should be the **list of bigrams and their frequency**. Display the top 10 most common bigrams and their frequency.\n",
        "*   Write a function to generate all **unique trigrams** from all documents in the dataset. The input of this function should be the concatenated dataset and the output should be the **list of trigrams and their frequency**. Display the top 10 most common trigrams and their frequency.\n",
        "*   Write a function to extract all **unique NOUN and VERB** tokens. The input of this function should be the concatenated dataset and the output should be **two lists: one of the NOUN tokens and their frequency, the other list should be the VERB tokens and their counts**. Display the top 10 most common NOUN and VERB tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mxJC5eFiyfq"
      },
      "source": [
        "###**Generating and displaying TOP 10 unique bigrams**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZS_ol_mLCco"
      },
      "source": [
        "**Function to generate unique bigrams and their frequency**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZhSe-K8t__pj"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def generate_bigrams(concatenated_dataset):\n",
        "\n",
        "    #In order to avoid to exceed the RAM limit, we will split the concatenated dataset in batches of 10\n",
        "    text_lines = concatenated_dataset.split(\"\\n\")\n",
        "    for i in range(len(text_lines)):\n",
        "        #Removing line breaks\n",
        "        text_lines[i] = re.sub(r'(\\n.?)+', r' ', text_lines[i])\n",
        "        #Removing tab delimiters\n",
        "        text_lines[i] = re.sub(r'(\\t.?)+', r' ', text_lines[i])\n",
        "        #Removing extra whitespaces\n",
        "        text_lines[i] = re.sub(' +', ' ', text_lines[i])\n",
        "\n",
        "    num_lines = len(text_lines)\n",
        "    batches = int(num_lines/10)\n",
        "\n",
        "    chunks = [text_lines[i:i + batches] for i in range(0, len(text_lines), batches)]\n",
        "\n",
        "    #Counting the bigrams\n",
        "    last_gram_chunk = \"\"\n",
        "    bigram_frequency = {}\n",
        "    for i in range(len(chunks)):\n",
        "        temp_chunk_joined = ''.join(chunks[i])\n",
        "        chunk_play_grams = nlp(temp_chunk_joined)\n",
        "      \n",
        "        if i != 0:\n",
        "            temp_bigram = last_gram_chunk+\" \"+chunk_play_grams[0].text\n",
        "            if (temp_bigram in bigram_frequency):\n",
        "                bigram_frequency[temp_bigram] += 1\n",
        "            else:\n",
        "                bigram_frequency[temp_bigram] = 1\n",
        "\n",
        "        for j in range(len(chunk_play_grams)-1):\n",
        "              temp_bigram = chunk_play_grams[j].text+\" \"+chunk_play_grams[j+1].text\n",
        "              if (temp_bigram in bigram_frequency):\n",
        "                bigram_frequency[temp_bigram] += 1\n",
        "              else:\n",
        "                bigram_frequency[temp_bigram] = 1\n",
        "\n",
        "              if j == len(chunk_play_grams) -2:\n",
        "                  last_gram_chunk = chunk_play_grams[j+1].text\n",
        "        #To avoid RAM being full we delete the old chunk\n",
        "        del chunk_play_grams\n",
        "\n",
        "    sorted_dict = dict(sorted(bigram_frequency.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    #Returns the results as a list of tuples\n",
        "    return [(k, v) for k, v in sorted_dict.items()]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhDT68oZgNxC"
      },
      "source": [
        "**Displaying the top 10 bigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "lQlPo6ipgRBA",
        "outputId": "de085ba6-1842-42d7-df97-78345c1c1879"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "list_bigrams = generate_bigrams(full_play)\n",
        "print(\"\\033[1m Top 10 bigrams and their frequency \\033[0m \\n\")\n",
        "result = list_bigrams[:10]\n",
        "\n",
        "df_top_bigrams = pd.DataFrame(columns=['Bigram','Frequency'])\n",
        "df_top_bigrams['Bigram'] = [a_tuple[0] for a_tuple in result]\n",
        "df_top_bigrams['Frequency'] = [a_tuple[1] for a_tuple in result]\n",
        "\n",
        "print(df_top_bigrams)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m Top 10 bigrams and their frequency \u001b[0m \n",
            "\n",
            "   Bigram  Frequency\n",
            "0   , and       7222\n",
            "1     , I       4175\n",
            "2   , And       3696\n",
            "3     . I       2837\n",
            "4     , [       2724\n",
            "5    , my       2204\n",
            "6    I am       1626\n",
            "7   you ,       1577\n",
            "8   , sir       1560\n",
            "9  in the       1495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fk8J_8qQjTzc"
      },
      "source": [
        "###**Generating and displaying TOP 10 unique trigrams**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnAb1bxkgsre"
      },
      "source": [
        "**Function to generate unique trigrams and their frequency**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtzS5YOOgsxH"
      },
      "source": [
        "def generate_trigrams(concatenated_dataset):\n",
        "\n",
        "    #In order to avoid to exceed the RAM limit, we will split the concatenated dataset in batches of 10\n",
        "    text_lines = concatenated_dataset.split(\"\\n\")\n",
        "    for i in range(len(text_lines)):\n",
        "        #Removing line breaks\n",
        "        text_lines[i] = re.sub(r'(\\n.?)+', r' ', text_lines[i])\n",
        "        #Removing tab delimiters\n",
        "        text_lines[i] = re.sub(r'(\\t.?)+', r' ', text_lines[i])\n",
        "        #Removing extra whitespaces\n",
        "        text_lines[i] = re.sub(' +', ' ', text_lines[i])\n",
        "\n",
        "    num_lines = len(text_lines)\n",
        "    batches = int(num_lines/10)\n",
        "\n",
        "    chunks = [text_lines[i:i + batches] for i in range(0, len(text_lines), batches)]\n",
        "\n",
        "    #Counting the bigrams\n",
        "    last_gram_chunk = \"\"\n",
        "    second_last_gram_chunk = \"\"\n",
        "    trigram_frequency = {}\n",
        "    for i in range(len(chunks)):\n",
        "        temp_chunk_joined = ''.join(chunks[i])\n",
        "        chunk_play_grams = nlp(temp_chunk_joined)\n",
        "      \n",
        "        if i != 0:\n",
        "            temp_bigram = second_last_gram_chunk+\" \"+last_gram_chunk+\" \"+chunk_play_grams[0].text\n",
        "            if (temp_bigram in trigram_frequency):\n",
        "                trigram_frequency[temp_bigram] += 1\n",
        "            else:\n",
        "                trigram_frequency[temp_bigram] = 1\n",
        "            \n",
        "            temp_bigram = last_gram_chunk+\" \"+chunk_play_grams[0].text+\" \"+chunk_play_grams[1].text\n",
        "            if (temp_bigram in trigram_frequency):\n",
        "                trigram_frequency[temp_bigram] += 1\n",
        "            else:\n",
        "                trigram_frequency[temp_bigram] = 1\n",
        "          \n",
        "\n",
        "        for j in range(len(chunk_play_grams)-2):\n",
        "              temp_bigram = chunk_play_grams[j].text+\" \"+chunk_play_grams[j+1].text+\" \"+chunk_play_grams[j+2].text\n",
        "              if (temp_bigram in trigram_frequency):\n",
        "                trigram_frequency[temp_bigram] += 1\n",
        "              else:\n",
        "                trigram_frequency[temp_bigram] = 1\n",
        "\n",
        "              if j == len(chunk_play_grams) -3:\n",
        "                  second_last_gram_chunk = chunk_play_grams[j+1].text+\" \"+chunk_play_grams[j+2].text\n",
        "              if j == len(chunk_play_grams) -2:\n",
        "                  last_gram_chunk = chunk_play_grams[j+1].text+\" \"+chunk_play_grams[j+1].text\n",
        "        #To avoid RAM being full we delete the old chunk\n",
        "        del chunk_play_grams\n",
        "\n",
        "    sorted_dict = dict(sorted(trigram_frequency.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    #Returns the results as a list of tuples\n",
        "    return [(k, v) for k, v in sorted_dict.items()]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTLe4fings_g"
      },
      "source": [
        "**Displaying the top 10 trigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KroOpRI1gtEK",
        "outputId": "7c6a5688-21d6-41ac-c8f8-25c3790011e4"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "list_trigrams = generate_trigrams(full_play)\n",
        "print(\"\\033[1m Top 10 trigrams and their frequency \\033[0m \\n\")\n",
        "result = list_trigrams[:10]\n",
        "\n",
        "df_top_trigrams = pd.DataFrame(columns=['Trigram','Frequency'])\n",
        "df_top_trigrams['Trigram'] = [a_tuple[0] for a_tuple in result]\n",
        "df_top_trigrams['Frequency'] = [a_tuple[1] for a_tuple in result]\n",
        "\n",
        "print(df_top_trigrams)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m Top 10 trigrams and their frequency \u001b[0m \n",
            "\n",
            "     Trigram  Frequency\n",
            "0    , sir ,        991\n",
            "1     , [ to        876\n",
            "2  , my lord        835\n",
            "3     , [ as        717\n",
            "4     ' th '        580\n",
            "5  my lord ,        512\n",
            "6  , [ aside        444\n",
            "7    , sir .        440\n",
            "8   , I will        381\n",
            "9    , I 'll        364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WDrZdpejW0K"
      },
      "source": [
        "###**Extracting unique NOUN and VERB tokens**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mw7sJr2jhaY"
      },
      "source": [
        "**Function to extract unique NOUN abd VERB tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3_g2BUBjp-7"
      },
      "source": [
        "def get_verb_noun(concatenated_dataset):\n",
        "\n",
        "    #In order to avoid to exceed the RAM limit, we will split the concatenated dataset in batches of 10\n",
        "    text_lines = concatenated_dataset.split(\"\\n\")\n",
        "    for i in range(len(text_lines)):\n",
        "        #Removing line breaks\n",
        "        text_lines[i] = re.sub(r'(\\n.?)+', r' ', text_lines[i])\n",
        "        #Removing tab delimiters\n",
        "        text_lines[i] = re.sub(r'(\\t.?)+', r' ', text_lines[i])\n",
        "        #Removing extra whitespaces\n",
        "        text_lines[i] = re.sub(' +', ' ', text_lines[i])\n",
        "\n",
        "    num_lines = len(text_lines)\n",
        "    batches = int(num_lines/10)\n",
        "\n",
        "    chunks = [text_lines[i:i + batches] for i in range(0, len(text_lines), batches)]\n",
        "\n",
        "    #Counting the bigrams\n",
        "    noun_frequency = {}\n",
        "    verb_frequency = {}\n",
        "    for i in range(len(chunks)):\n",
        "        temp_chunk_joined = ''.join(chunks[i])\n",
        "        chunk_play_grams = nlp(temp_chunk_joined)\n",
        "\n",
        "        for j in range(len(chunk_play_grams)):\n",
        "              \n",
        "              if chunk_play_grams[j].pos_ == \"NOUN\":\n",
        "                  noun_temp = chunk_play_grams[j].text\n",
        "                  if (noun_temp in noun_frequency):\n",
        "                    noun_frequency[noun_temp] += 1\n",
        "                  else:\n",
        "                   noun_frequency[noun_temp] = 1\n",
        "              \n",
        "              if chunk_play_grams[j].pos_ == \"VERB\":\n",
        "                  verb_temp = chunk_play_grams[j].text\n",
        "                  if (verb_temp in verb_frequency):\n",
        "                    verb_frequency[verb_temp] += 1\n",
        "                  else:\n",
        "                   verb_frequency[verb_temp] = 1\n",
        "\n",
        "        #To avoid RAM being full we delete the old chunk\n",
        "        del chunk_play_grams\n",
        "\n",
        "    sorted_noun = dict(sorted(noun_frequency.items(), key=lambda item: item[1], reverse=True))\n",
        "    sorted_verb = dict(sorted(verb_frequency.items(), key=lambda item: item[1], reverse=True))\n",
        "\n",
        "    #Returns the results as a list with two lists of tuples\n",
        "    return [[(k, v) for k, v in sorted_noun.items()],[(k, v) for k, v in sorted_verb.items()]]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEdA5XnQjlsw"
      },
      "source": [
        "**Displaying the top 10 NOUN and VERB tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q-qQwVzKjqdv",
        "outputId": "9fe5ed6a-7550-41b7-b945-e3e7c522d5a2"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "list_nounverbs = get_verb_noun(full_play)\n",
        "print(\"\\033[1m Top 10 NOUNS and VERBS and their frequency \\033[0m \\n\")\n",
        "\n",
        "result_noun = list_nounverbs[0][:10]\n",
        "result_verb = list_nounverbs[1][:10]\n",
        "\n",
        "df_top_nounverbs = pd.DataFrame(columns=['Noun', 'Frequency (Noun)', 'Verb', 'Frequency (Verb)'])\n",
        "df_top_nounverbs['Noun'] = [a_tuple[0] for a_tuple in result_noun]\n",
        "df_top_nounverbs['Frequency (Noun)'] = [a_tuple[1] for a_tuple in result_noun]\n",
        "df_top_nounverbs['Verb'] = [a_tuple[0] for a_tuple in result_verb]\n",
        "df_top_nounverbs['Frequency (Verb)'] = [a_tuple[1] for a_tuple in result_verb]\n",
        "\n",
        "print(df_top_nounverbs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1m Top 10 NOUNS and VERBS and their frequency \u001b[0m \n",
            "\n",
            "     Noun  Frequency (Noun)    Verb  Frequency (Verb)\n",
            "0     man              1656    will              4213\n",
            "1    love              1368   shall              3161\n",
            "2     sir              1218   would              1972\n",
            "3   heart               915     'll              1830\n",
            "4       t               903     can              1756\n",
            "5    time               882    know              1482\n",
            "6  father               881    make              1470\n",
            "7     men               825     may              1442\n",
            "8    life               780  should              1415\n",
            "9    hand               720    must              1394\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rriarw4P__uk"
      },
      "source": [
        "###**Answer the following questions**\n",
        "\n",
        "**What do you think the most common bigrams and trigrams could be useful for?** \n",
        "With the extraction of the most common bigrams and trigrams, they could be used for prediction. For example, it could be useful to automatically autocomplete a search (like the one implemented from Google).\n",
        "\n",
        "**There is a particular method we have seen in this class to characterize a corpus that could benefit from having these bigrams/trigrams when the underlying text corpus can’t be shared. Please talk about this.** That particular method is related by training a model (based on the probabilities of an n-gram given a text corpus) to generate text based on the probability threshold. Given n-grams, the higher the n is, the generated text will make more sense, although the process will be slower because it requires lot of CPU resources. One of the recommendations to get good results is that we need to train robust models that generalize, in order to avoid getting zero probabilities n-grams, and getting very bad results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-_ogHrWwkh9"
      },
      "source": [
        "##**EXERCISE 4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOUBIAv_wolT"
      },
      "source": [
        "**(30 points)** Using the dataset: **Ask0729**, found in Exam files, write two functions to extract all dates found in this dataset. The input of these functions should take the dataset as input, and output a list of dates. You should use two different methods, one per function.\n",
        "\n",
        "*   First method: **using SpaCy** (this is a big enough hint)\n",
        "*   Second method: using **regular expressions**.\n",
        "*   Print to screen to compare the results from the two functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzMWCfuzxqnG"
      },
      "source": [
        "import zipfile\n",
        "#Downloading the Ask0729 dataset\n",
        "!wget https://github.com/LuisRobles18/NLP/raw/main/Ask0729.zip -O Ask0729.zip\n",
        "clear_output()\n",
        "\n",
        "#Obtaining the ZIP file\n",
        "my_zip = zipfile.ZipFile('Ask0729.zip')\n",
        "storage_path = '.'\n",
        "#Each txt file inside the ZIP file will be stored in a list\n",
        "ask_dataset= \"\"\n",
        "for file in my_zip.namelist():\n",
        "    #Only TXT files will be accepted to be stored in the documents and documents name lists\n",
        "    #For some reason MAC OS's generates an extra folder called \"__MACOSX\" which will be excluded\n",
        "    if my_zip.getinfo(file).filename.endswith('.txt') and not my_zip.getinfo(file).filename.startswith('__MACOSX'):\n",
        "        ask_dataset = my_zip.read(my_zip.getinfo(file).filename).decode('utf-8')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqSP3H5-w7PW"
      },
      "source": [
        "###**First method - Using SpaCy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9AbYHO-w7VE"
      },
      "source": [
        "def get_dates_spacy(concatenated_dataset):\n",
        "    list_dates = []\n",
        "    doc = nlp(concatenated_dataset)\n",
        "    for entity in doc.ents:\n",
        "        if entity.label_ == \"DATE\":\n",
        "            list_dates.append(entity.text)\n",
        "    \n",
        "    return list_dates"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLkryLF4w7aJ"
      },
      "source": [
        "###**Second method - Using Regular Expressions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieTGarxDw7fy"
      },
      "source": [
        "import re\n",
        "def get_dates_regex(concatenated_dataset):\n",
        "  list_results = []\n",
        "  #Search for any date in different formats\n",
        "  list_results.append(re.findall( r'^([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])(\\.|-|\\/)([1-9]|0[1-9]|1[0-2])(\\.|-|\\/)([0-9][0-9]|19[0-9][0-9]|20[0-9][0-9])$|\\\n",
        "  ^([0-9][0-9]|19[0-9][0-9]|20[0-9][0-9])(\\.|-|\\/)([1-9]|0[1-9]|1[0-2])(\\.|-|\\/)([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])$', concatenated_dataset))\n",
        "  #Example: 15 Jan 2021 or 15\n",
        "  list_results.append(re.findall( r'\\d{2}\\s(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{4}|\\\n",
        "  \\d{2}\\s(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)', concatenated_dataset))\n",
        "  #Example: 15 January 2021 or 15 January\n",
        "  list_results.append(re.findall( r'\\d{2}\\s(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{4}|\\\n",
        "  \\d{2}\\s(?:January|February|March|April|May|June|July|August|September|October|November|December)', concatenated_dataset))\n",
        "  #Example: Jan 15 2021 or Jan 15\n",
        "  list_results.append(re.findall( r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}\\s\\d{4}|\\\n",
        "  (?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)\\s\\d{2}', concatenated_dataset))\n",
        "  #Example: January 15 2021 or January 15\n",
        "  list_results.append(re.findall( r'(?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{2}\\s\\d{4}|\\\n",
        "  (?:January|February|March|April|May|June|July|August|September|October|November|December)\\s\\d{2}', concatenated_dataset))\n",
        "  return list_results"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAzZhympw7uG"
      },
      "source": [
        "###**Showing the results from both methods**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgbnEP071-1r"
      },
      "source": [
        "**Using SpaCy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ozwxItnOw7yI",
        "outputId": "b570d05c-5b60-4d72-98d2-10f7bd1dde3a"
      },
      "source": [
        "print(get_dates_spacy(ask_dataset))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['up to 5 years', 'today', 'today', 'today', 'one week', 'MA 02143', 'daily', 'today', '3+ Nights & Save', 'this week', 'weekend', 'this week', '2 Weeks', 'the year', 'tomorrow', 'Wednesday', 'Saturday', 'the 6 year old', 'tomorrow', '25 years', 'year end 2000', 'under 40/over 40', 'junior-year', 'all summer', 'next week', 'yesterday', 'Monday', 'Thursday 4:00PM', 'July 31, 2014', '30 June 2012', 'April 15th', 'this year', 'this time', 'next year', 'years', 'Friday', 'Monday', 'December 7th', 'yesterday', 'yesterday', 'tomorrow', '14 day', '2 days', 'years', 'tomorrow', 'tomorrow', 'tomorrow', 'the next year', 'Sunday', 'a day', '12 MONTHS', 'July 4, 2012', 'Tomorrow', 'this week', 'Tuesday, March 20, 2001', 'annual', '21st Century', 'this week', 'tomorrow', 'next Wednesday', 'the old days', 'Next week', 'April', 'the 19th', 'August 31st', 'the year', 'only a week', 'June 23, 2000', 'today', 'Last week', 'Friday', 'the week', 'the 31st of March', '1 Year Giveaway', 'Thanksgiving', 'Today', 'Tomorrow', '2 weeks ago', 'every day', 'weekly', 'annual', 'tomorrow', 'A few weeks ago', 'this week', '1999', '2000', 'annual', '2081', 'Monday', 'March 8, 2013', 'the late 18th century', 'last week', 'today', 'next week', 'Sunday', 'the next two weeks', 'a few weeks', 'today', '1850-1940 1.1.0', 'February 28, 2014', 'the last year', 'the weeks', 'months ahead', '2 day', 'today', '30 June', 'the next 75 days', '2000', 'about a month', \"last Tuesday'Wednesday's\", 'Thursday', 'this year', '11 July', '1 year', 'April 2011', 'Day 5', 'April 5-19 15,000/day', 'Wednesday, June 27', 'the first weekend', 'April', 'Jan 26th', 'the weekend', 'the week of January 15th', 'that week', 'friday', 'yesterday', 'Thursday', 'approximately 2 years', 'the next 3-6 months', 'yesterday', 'August 2013', 'August 22, 2012', 'August 23, 2012', 'August 8, 2012', 'this Monday, September 2nd, 2013', 'a week or so ago', 'Friday', '2001', 'today', 'tomorrow', 'last week', 'tomorrow', 'yesterday', 'Monday', 'Tuesday', 'the days/weeks ahead', 'Thursday', '36 months', 'Wednesday', 'Thursday', 'Tuesday, October 24 - available 9:30 am to 1:00 pm', 'daily', 'August', \"Dec. '95\", \"Dec. '95\", 'today', 'tomorrow', 'Wednesday, July 31, 2013', 'the 16th of August', 'Monday, January 14, 2013', 'Friday', 'Friday', 'the first two days', '17 days ago', 'Nov. 8, 2000', 'today', 'the end of the month', 'five-year', 'May 16th', '7', 'quarterly', 'April 16', '2001', 'the school year', 'Weekly', 'Monday, April 23rd', 'Weekly', 'Monday, January 29', 'Thursday, June 14, 2001', 'St 65', 'Friday', 'Friday', 'Friday', 'Christmas', 'July', 'tomorrow', 'tomorrow', 'August', 'the week of April 16', 'April 16, 17', '18 or 19th', 'today', 'Thursday', 'tomorrow', 'today', 'the 13th and 14th', 'tomorrow', 'Monday', 'another month', 'weeks', 'mid-May', 'today', 'tomorrow', 'this week', 'next week', 'this week', 'the day', 'tomorrow', 'today', 'this weeks', 'Monday', 'the past few winters', 'tomorrow', 'tomorrow', 'today', 'tomorrow', 'this week', 'next week', 'next week', 'early November', 'tomorrow', 'this season', 'yesterday', 'a day', 'days', 'today', 'quarter this year', 'Monday', 'Tuesday', 'Monday', 'tomorrow', 'Thursday', 'today', 'tomorrow', 'Tuesday', 'today', 'next week', 'several business days', 'today', 'today', 'half days', 'next week', 'tomorrow', 'Wed of next week', 'this summer', 'Nov. 29', 'a couple of weeks', 'today', 'yesterday', 'Wednesday, October 25', 'later this week', 'next week', 'the day', 'tomorrow - deal 169576', 'tomorrow', 'last year', 'Friday', 'July', 'no quarter', 'the next 60-90 days', 'one month', 'today', 'last week', 'today', 'this week', 'all day', 'tomorrow', 'next week', 'the week', 'tomorrow', 'about 10 days', 'this week', 'today', 'February', 'monthly', 'next week', 'every day', 'the next couple of hours', 'Friday', 'end of day', 'today', 'Monday', 'tomorrow', 'Monday', 'today', 'today', '9 years', 'the next ten days', 'January', 'December', 'daily', 'GoHealthInsurance', 'January 16, 2013 to January 18, 2013', 'today', '10010', 'the end of April', 'tomorrow', 'two year', 'this year', 'monthly', 'every month', 'this month', '2 Weeks', 'the 13th', 'the 12th', 'the weeks', 'today', 'Halloween', 'next week', 'December', 'NaNoWriMo 2013', 'the last 6 months', 'each day', 'Monday', 'Wednesday', 'this week', 'July', 'June 2011 13', 'Day 5', 'June', 'an awesome month', 'the last several months', 'Thursday', 'the weekend', 'daily', 'Half-Year', 'July 11', '380571', 'LAST DAY', 'LAST DAY', 'Last Week', 'Last year', 'every week', 'Wednesday', 'Saturday', 'the 14th of May.', 'a week', 'Aug. 3, 2000', 'March 2011 12: Period Day 1 13:', '7 28', 'Day 1', 'Wednesday, December 31st', 'Monday', 'Monday', 'Monday through Friday', 'Monday, April 16th', 'Monday, August 6th', 'Monday, June 4th', 'Monday', 'May 14th', 'this week', 'several weeks ago', 'Feb. 20, 2001', 'Tuesday', 'the first quarter', 'January', 'today', 'this week', 'Feb 26, 2013', 'Friday, October 26, 2001', 'July 3, 2012', 'May 3rd', 'November 3', 'the days', 'Saturday', '30 days', 'One Week to Christmas', 'One day', 'Friday, May 25', 'tomorrow', 'the last several years', 'a few weeks ago', 'Monday', 'Tuesday, October 2 4, 2000', '1 year', 'the week of the 11th', 'tomorrow', 'Monday', 'monthly', 'today', 'Friday', 'Tuesday, June 12, 2001', '7 days', 'every month', 'Thursday', 'next week', 'Saturday', 'HE15-19', 'Monday', 'next week', 'Friday', 'Saturday January 19, 2002', 'Saturday', 'Monday', 'Sunday', 'Friday, April the 27th', 'Monday', 'tomorrow', 'tomorrow', 'last Thursday', 'September 4, 2011', 'Wednesday', 'the fall', 'Thursday', 'Sunday 28 August 2011', 'hundreds of years ago', 'the football season', 'tomorrow', 'yesterday', 'this year', 'tomorrow', 'Tomorrow', 'August 21, 2001', 'next summer', 'today', 'tomorrow', 'today', 'Monday, December 16th, 2013', 'tomorrow', 'Friday the 15th', 'Nov. 15th', 'Dec. 1', 'Wednesday', 'Wednesday', 'this week', 'Friday', 'next week', 'this week', 'yesterday', 'tomorrow', 'tomorrow', 'tomorrow', 'Wednesday', '33462', '33464', '33491', '33492', 'Feb. 8', 'Wednesday, August 28th', 'yesterday', 'the end of next week', 'August 18th', 'Sunday, July 14th', 'Four Weeks', '4 Weeks', '1-Hour', 'a day', 'next day', 'nightly', 'tomorrow', '2001', 'April 2010', 'this week', 'Sunday', 'tomorrow', 'today', '1989', '1989', 'October 17, 2013', 'tomorrow', 'next week', 'next week', 'This Friday', 'Saturday', '251415618', 'today', 'Friday', 'July 28 - August 4, 2001', 'every single day', 'the weekend', 'summer', 'This month', 'later this quarter', 'This week', '72', 'This week', 'Halloween', 'This week', 'This weekend', '2001', '2001', 'This year', 'today', '3:45pm - 10:00pm', 'Today', 'Today', 'Today', 'Today', 'Today', 'Today', 'Tomorrow', 'Wednesday', 'Thursday', 'Friday', 'Tomorrow', 'this week', 'year 2001', 'this week', 'today', 'Two Weeks', 'the next couple of weeks', 'this summer', '6 years', 'Thursday', 'Thursday & Friday', 'Thursday, January 25, 2001 08:36 AM?ET', 'Sept. 11', 'Thursday, September 19th', 'each day', 'daily', 'Saturday', 'between the days', 'July', 'Friday', 'Thursday', 'today', 'tomorrow', 'Thursday', 'later this week', 'this month', 'daily', 'monthly', 'this week', 'next week', 'Wednesday', '01&prudent', 'the past few months', \"this current year's\", 'a couple of days', 'Thursday', '2014-07-01', 'this week', 'next week', 'Wednesday', 'Labor Day', 'Friday of this week', 'Monday', 'this weekend', 'Monday 5 November', '19.30', '1201', '7 FREE days', 'this day', 'tomorrow', 'these last few weeks', 'Wednesday, August 2nd', 'last week', 'January', 'the new day', 'summer', 'maybe weeks', 'the coming decade', 'the coming decade', 'year', 'winter', 'the coming year', 'the next 3 business days', 'four weeks', 'the winter', 'the next week', 'Tuesday', 'a couple of weeks', 'tomorrow', 'daily', '1 Dec 2013', '30 day', 'Sunday 29 April 2012', 'January 31, 2013', 'Monday', 'today', 'today', 'Thursday, 31st January', 'the 29th', 'this week', 'today', 'today', 'Tuesday', 'each day', 'this week', 'may 1', 'may 2', '978/281-0744', '2 weeks', 'next week', 'Sept. 11', 'today', 'yesterday', 'weekly', '7 days', 'tomorrow', 'Sunday', 'another 30 days', 'Friday', 'Friday', 'Thursday June 20', 'January', 'Monday, October 8, 2001', 'the month of November', 'Sept. 20', 'tomorrow', 'Thursday', 'Friday', 'today', 'Sunday, December 8th, 2013', 'Monday, November 11th', 'Wednesday, September 25th', '415)244-6094', 'tomorrow', 'this June', 'Tuesday', 'the end of September', 'September 25', 'Thursday', '14 day', 'today', 'today', 'Halloween', 'today', 'tomorrow', 'tomorrow', 'this week', 'Tuesday', 'today', 'Monday', 'the day on Monday or', 'Tuesday', 'Saturday', 'Monday', 'Friday', 'tomorrow', 'Friday', 'this school year', 'This week', 'Wednesday', 'Wednesday', 'each day', '2001', 'up to 3 years', 'Thursday', 'today', 'Monday', 'Friday', 'this week', 'Tuesday', 'this Sunday', 'today', 'the beginning of the month', 'Saturday, March 25', 'this weekend', '713/853-5984', '713/853-6440', 'weekly', 'tomorrow', 'the past several months', 'Saturday', 'December 7', 'this week', 'Monday', 'Tuesday, January 8th', 'next week', 'Thursday', 'Friday', 'tomorrow', 'this weekend', 'Thursday, March 22', 'tomorrow', 'tomorrow', 'next week', 'tomorrow', 'this week', 'tomorrow', '1130', 'the weekend', 'today', 'Friday', 'daily', 'October 11th', 'this week', 'the 18th', 'Friday', 'Monday', 'November', 'this week', 'Tuesday', 'Tuesday', 'Wednesday', 'Monday', 'tomorrow', '2 day', 'Friday', 'Monday', 'last weekend', 'Monday', 'Jan 2000', 'yesterday', 'next week', 'that day', 'Tuesday, February 20, 2001', 'Tuesday', 'the weekend', '87-7449', 'today', 'Friday', '2001', 'tomorrow', 'July', 'Sunday', 'tomorrow', 'a year anniversary', 'the following week', 'today', 'early next week', 'March', 'March 28th', 'next week', 'tomorrow', 'tomorrow', 'tomorrow', 'Friday', 'next week', 'Monday, June 4th', 'all day', 'tomorrow', 'tomorrow', 'the end of the day', 'December 9', 'next Monday', 'tomorrow', 'the week', 'tomorrow', 'Thursday', 'today', 'this weekend', 'next week', 'next week', 'this weekend', 'the day and tomorrow', 'Thursday, November 29th', 'between now and Thursday', 'the week', 'next week', 'November 5th', 'today', 'this weekend', 'next week', 'this week', 'the next week', 'a couple days this week', 'next week', 'this week', 'tomorrow', 'a few weeks ago', 'Sunday', 'Monday', 'next week', 'Thursday', 'Wednesday', 'Thursday', 'this week', 'today', 'tomorrow', '3-0977', 'last Thursday', 'tomorrow', 'Thursday', 'Thursday', 'Friday', '3 nights', 'sunday', 'March', '21 years old', 'December', 'today', '251408768', 'Tuesday, August 27th, 2013', 'Friday', 'Friday', 'May 6 and May 24', 'November 11th and December 2nd, 2013', 'November 1, 2001', 'Monday, November 20th', 'a couple weeks', 'tomorrow', 'Monday, Jan. 22nd', 'Wednesday, Jan. 24th', 'today', 'the next few business days', 'the next couple of weeks', 'Sunday earlier', 'August 17', 'Thursday', 'next week', 'last week', 'XXXXXXXXX2159', 'Wednesday', 'April 12th', '2:30pm', 'March', 'Monday', '2001', 'Thursday', 'Friday', 'Monday', 'Tuesday', 'tomorrow', 'daily', 'tomorrow (Sunday', 'today', 'next week', 'every Friday', 'Wednesday', 'Tuesday', 'tomorrow', 'Friday', 'later this week', 'a few days', 'every week', 'this week', 'Sunday', 'Thursday', 'April 30', 'tomorrow', 'Friday', 'Monday', '2001', 'this next week', 'Saturday', 'Sunday', 'Tuesday', 'next week', 'next Monday', 'tomorrow', 'a later date', 'tomorrow', 'Friday', 'tomorrow', 'today', 'next week', 'last week', 'Monday', 'next Wednesday', 'Thursday', 'Saturday', '2000', 'Friday', 'two weeks', 'quarterly', 'Monday', 'late Oct.', 'today', 'tomorrow', 'tomorrow', 'Friday', 'the next few days', 'next week', 'annual', 'May 12, 2001', 'tomorrow', 'Monday', 'tomorrow', 'Monday', 'next week', 'Sunday', 'Thursday', 'Wednesday', 'Monday', 'Wednesday', 'Monday', 'today', 'Monday', 'next week', '10/31', 'Monday, December 18', 'Intra-month', 'next Monday', 'the end of the week', 'tomorrow', 'last week', 'Wednesday', 'next week', 'Wednesday, Dec. 13th', 'tomorrow', 'summer', 'April', 'May', 'summer', 'next week', 'Monday', 'Monday', 'tomorrow', 'Friday', 'Monday', '627-8172', 'next Tuesday/Wednesday', 'Thursday', 'between now and Monday', 'Friday', 'a day', 'Sunday', 'December', 'today', 'Monday', 'next week', '301/652-7877', 'tommorrow', 'today', 'tomorrow', 'Monday', 'Saturday', 'Friday', 'Friday', 'the next week', 'March 12', 'this week', 'last Sunday', 'Labor Day', 'the 17th', 'today', 'Christmas', 'tomorrow', 'season', 'season', 'today', 'tomorrow', 'Christmas', 'Friday, August 4th', '26301', 'this coming Monday', 'every other week', 'a week', 'tomorrow', 'monthly', 'last week', 'Thursday', '7-10', '1100', 'Monday', 'two days', 'Wednesday', 'Thursday', '2014', 'Tuesday, September 30th', 'January', 'these days', 'this week', 'Thursday', 'next week', 'early next week', 'Monday', '2000', 'this week', 'yesterday', 'the weekend', 'Monday', 'next week', 'the following week', 'next week', 'Tuesday', 'this week', 'the end of January', 'mid January', 'Wednesday', 'Thursday', 'early October', 'the next couple weeks', 'Friday', 'early next week', 'today', 'this weekend', 'this weekend', 'next summer', 'today', 'Week 2013', 'the next month', 'April 16', 'Monday', 'today', '15s', 'this week', 'today', 'next Monday', 'Thursday', 'all next week', 'next week', 'the next many months', 'September 5, 2000', 'tomorrow', 'weekly', 'Friday', 'weekly', 'this week', 'Dec. 17th', 'Thursday', 'this weekend', '2000', 'year', 'tomorrow', 'Thursday, November 28', 'Monday', 'Saturday', 'tomorrow', 'that day', 'this week', 'monthly', 'the 8:30 call tomorrow', 'next week', 'next year', 'this week', 'tomorrow', 'the next few weeks', 'Sunday', 'Saturday', 'April 11', 'same week', 'Saturday', 'Tuesday the 24th', 'Sunday', 'the next couple of days', 'Monday', 'next week', 'the weekend', 'this weekend', 'next Thursday', 'the last several weeks', 'Thursday', 'tomorrow', 'Sunday', 'tomorrow', 'the 25th - 28th', 'the 28th', 'tomorrow', 'Wednesday', '37323']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTSBx9n-2GZU"
      },
      "source": [
        "**Using Regex**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjpecJ-v2Ggj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2a1eefdb-23a6-437a-b388-5b69c6627ae5"
      },
      "source": [
        "print(get_dates_regex(ask_dataset))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[], [], ['30 June 2012', '28 August 2011', '29 April 2012'], [], []]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBZGVAhow73q"
      },
      "source": [
        "###**Answer the following questions**\n",
        "\n",
        "**Which one of the two approaches was better?** I think the first one (SpaCy) was better\n",
        "\n",
        " **Why do you think so?** Because SpaCy extracted many possible types of dates it can be found on a text, and we can make some adjustments to limit which types of dates we want to show (For example, if we want to show Dates in numerical format). While for the regex approach, it was really difficult trying to capture all possible combinations a date could have. Even using complex patterns to match dates in several ways, I was only able to extract only 3 dates, and comparing to the one from SpaCy, we see there are definetly more dates inside the text.\n",
        "\n",
        " **Would you use any of these approaches? Or a different one?** I would definetly use SpaCy because it is faster and it doesn't require a lot of time to code. Also, as explained before, I could customize this search, by creating some rules to only extract certain types of dates if needed (Dates in numerical format, or Dates with month as string, or Dates with only month and day, etc).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgZlVSHl_T2T"
      },
      "source": [
        "##**EXERCISE 5**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqFRZnef_ZOD"
      },
      "source": [
        "**(30 points)** Train an LSTM model to classify the [Cornell Movie Review data](http://www.cs.cornell.edu/people/pabo/movie-review-data/)\n",
        "using the [polarity_dataset V2.0](http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz). You can use the code for class 19, but take a note that you will have to adapt some of the parameters like: \n",
        "\n",
        "*   Review size = **450**\n",
        "*   Epochs = **5**\n",
        "*   85% for **training** and 15% for **testing**\n",
        "\n",
        "Once you build the model, please display the sklearn classification report. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97N-S2H7AMSv"
      },
      "source": [
        "###**Downloading and exporting the dataset to a dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sAN2MhvHO_3O"
      },
      "source": [
        "import tarfile\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#Downloading the polarity dataset from the Cornell Movie Review data\n",
        "!wget http://www.cs.cornell.edu/people/pabo/movie-review-data/review_polarity.tar.gz -O review_polarity.tar.gz\n",
        "clear_output()\n",
        "\n",
        "#We ensure there is no zipped files with the same name\n",
        "if os.path.exists(\"review_polarity.zip\"):\n",
        "  os.remove(\"review_polarity.zip\")\n",
        "\n",
        "#Converting Gzip file to zip file\n",
        "#The reason to convert it to Zip file, is because python gzip module is not able to read the filenames inside the\n",
        "#file (without extracting them). Converting it to a ZIP file will allow to know the path of each file inside it and to\n",
        "#separate the files (one from the \"pos folder\", and the other one from the \"neg\" folder)\n",
        "tar_file = tarfile.open( name='review_polarity.tar.gz', mode='r|gz' )\n",
        "zip_file = zipfile.ZipFile( file='review_polarity.zip', mode='a', compression=zipfile.ZIP_DEFLATED)\n",
        "for m in tar_file:\n",
        "    f = tar_file.extractfile(m)\n",
        "    fl = f.read()\n",
        "    fn = m.name\n",
        "    zip_file.writestr(fn, fl)\n",
        "tar_file.close()\n",
        "zip_file.close()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Tuy7WZDuAMeV",
        "outputId": "a28f9802-86ae-4d99-b61b-7a5a71f2cd95"
      },
      "source": [
        "#All the files will be stored in a pandas dataframe\n",
        "text_reviews = []\n",
        "label_reviews= []\n",
        "#The value for negative reviews will be 0, and for positive reviews 1\n",
        "target_names = [\"negative_reviews\",\"positive_reviews\"]\n",
        "\n",
        "#Openning the dataset ZIP file and extracting the polarity reviews\n",
        "my_zip = zipfile.ZipFile('review_polarity.zip')\n",
        "storage_path = '.'\n",
        "\n",
        "for file in my_zip.namelist():\n",
        "    #We will extract the negative reviews first to the list\n",
        "    if file.startswith('txt_sentoken/neg/') and file.endswith('.txt'):\n",
        "        with my_zip.open(file,\"r\") as doc:\n",
        "            #Since the files read are from a zip file, we must convert them from binary to string using the decode function\n",
        "            text_reviews.append(doc.read().decode())\n",
        "            #This will be used for the next exercise. For negative reviews, the value for the target will be 0\n",
        "            label_reviews.append(0)\n",
        "\n",
        "for file in my_zip.namelist():\n",
        "    #Then we will extract the positive reviews to the list\n",
        "    if file.startswith('txt_sentoken/pos/') and file.endswith('.txt'):\n",
        "        with my_zip.open(file,\"r\") as doc:\n",
        "            #Since the files read are from a zip file, we must convert them from binary to string using the decode function\n",
        "            text_reviews.append(doc.read().decode())\n",
        "            #This will be used for the next exercise. For positive reviews, the value for the target will be 1\n",
        "            label_reviews.append(1)\n",
        "\n",
        "clear_output()\n",
        "df_polarity_dataset = pd.DataFrame(columns=['Text', 'Label'])\n",
        "df_polarity_dataset['Text'] = text_reviews\n",
        "df_polarity_dataset['Label'] = label_reviews\n",
        "df_polarity_dataset = df_polarity_dataset.sample(frac=1)\n",
        "\n",
        "df_polarity_dataset.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>chill factor is a carbon copy of speed with on...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1312</th>\n",
              "      <td>synopsis : shrek ( myers ) is an ogre living i...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>the tagline for this film is : \" some houses a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>seen at : amc old pasadena 8 , pasadena , ca (...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1370</th>\n",
              "      <td>i didn't realize how apt the name of this movi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text  Label\n",
              "436   chill factor is a carbon copy of speed with on...      0\n",
              "1312  synopsis : shrek ( myers ) is an ogre living i...      1\n",
              "302   the tagline for this film is : \" some houses a...      0\n",
              "681   seen at : amc old pasadena 8 , pasadena , ca (...      0\n",
              "1370  i didn't realize how apt the name of this movi...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKdXYtEhAMoo"
      },
      "source": [
        "###**Splitting data training and validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "Zud8cLrUAMwz",
        "outputId": "1557010e-0de4-478b-93ea-56408c3a606c"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "list_data = list(df_polarity_dataset['Text'])\n",
        "list_target = list(df_polarity_dataset['Label'])\n",
        "\n",
        "training_data, test_data, training_target, test_target = train_test_split(\n",
        "    list_data, list_target, test_size=0.15, random_state = 12345)\n",
        "\n",
        "df_summary_split = pd.DataFrame(columns=['Split group','Percentage', 'Negative Reviews', 'Positive Reviews', 'Size'])\n",
        "df_summary_split.loc[len(df_summary_split), :] = ['Training Data','85%', training_target.count(0), \n",
        "                                                  training_target.count(1), len(training_data)]\n",
        "df_summary_split.loc[len(df_summary_split), :] = ['Testing Data','15%', test_target.count(0), \n",
        "                                                  test_target.count(1), len(test_data)]\n",
        "df_summary_split.loc[len(df_summary_split), :] = ['All (Total)', '100%', test_target.count(0)+training_target.count(0), \n",
        "                                                  test_target.count(1)+training_target.count(1), len(list_data)]\n",
        "df_summary_split['Size'] = df_summary_split['Size'].apply(lambda x: \"{:,}\".format(x))\n",
        "df_summary_split['Negative Reviews'] = df_summary_split['Negative Reviews'].apply(lambda x: \"{:,}\".format(x))\n",
        "df_summary_split['Positive Reviews'] = df_summary_split['Positive Reviews'].apply(lambda x: \"{:,}\".format(x))\n",
        "df_summary_split"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Split group</th>\n",
              "      <th>Percentage</th>\n",
              "      <th>Negative Reviews</th>\n",
              "      <th>Positive Reviews</th>\n",
              "      <th>Size</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Training Data</td>\n",
              "      <td>85%</td>\n",
              "      <td>843</td>\n",
              "      <td>857</td>\n",
              "      <td>1,700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Testing Data</td>\n",
              "      <td>15%</td>\n",
              "      <td>157</td>\n",
              "      <td>143</td>\n",
              "      <td>300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>All (Total)</td>\n",
              "      <td>100%</td>\n",
              "      <td>1,000</td>\n",
              "      <td>1,000</td>\n",
              "      <td>2,000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Split group Percentage Negative Reviews Positive Reviews   Size\n",
              "0  Training Data        85%              843              857  1,700\n",
              "1   Testing Data        15%              157              143    300\n",
              "2    All (Total)       100%            1,000            1,000  2,000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XcMrT5pR7ba"
      },
      "source": [
        "###**Data insight and pre-processing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "agPtgABJSCTU",
        "outputId": "b67b65f2-d25f-4c3e-ab8c-fd10ac04113f"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from numpy import array\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tf.random.set_seed(12345)\n",
        "# Supress deprecation warnings\n",
        "import logging\n",
        "logging.getLogger('tensorflow').disabled = True\n",
        "\n",
        "# Concatonate test and training datasets\n",
        "allreviews = np.concatenate((training_data, test_data), axis=0)\n",
        "\n",
        "# Review lengths across test and training whole datasets\n",
        "print(\"Maximum review length: {}\".format(len(max((allreviews), key=len))))\n",
        "print(\"Minimum review length: {}\".format(len(min((allreviews), key=len))))\n",
        "result = [len(x) for x in allreviews]\n",
        "print(\"Mean review length: {}\".format(np.mean(result)))\n",
        "\n",
        "# The length of reviews\n",
        "review_length = 450\n",
        "\n",
        "tokenizer = Tokenizer(num_words=review_length, lower=True)\n",
        "tokenizer.fit_on_texts(np.array(df_polarity_dataset['Text']))\n",
        "x_train = tokenizer.texts_to_sequences(np.array(training_data))\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=review_length)\n",
        "\n",
        "x_test = tokenizer.texts_to_sequences(np.array(test_data))\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=review_length)\n",
        "\n",
        "y_train = np.array(training_target)\n",
        "y_test = np.array(test_target)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Shape Training Review Data: \" + str(x_train.shape))\n",
        "print(\"Shape Training Class Data: \" + str(y_train.shape))\n",
        "print(\"Shape Test Review Data: \" + str(x_test.shape))\n",
        "print(\"Shape Test Class Data: \" + str(y_test.shape))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length: 14957\n",
            "Minimum review length: 91\n",
            "Mean review length: 3893.002\n",
            "\n",
            "Shape Training Review Data: (1700, 450)\n",
            "Shape Training Class Data: (1700,)\n",
            "Shape Test Review Data: (300, 450)\n",
            "Shape Test Class Data: (300,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtWTIFcpTqek"
      },
      "source": [
        "###**Creating and building LSTM Recurrent Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GUfX0jIqTqoO",
        "outputId": "8cabd614-f329-4e8d-8dac-1cf4badac55f"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# The Embedding Layer provides a spatial mapping (or Word Embedding) of all the \n",
        "# individual words in our training set. Words close to one another share context \n",
        "# and or meaning. This spatial mapping is learning during the training process.\n",
        "model.add(\n",
        "    tf.keras.layers.Embedding(\n",
        "        input_dim = 10000, # The size of our vocabulary \n",
        "        output_dim = 32, # Dimensions to which each words shall be mapped\n",
        "        input_length = review_length # Length of input sequences\n",
        "    )\n",
        ")\n",
        "\n",
        "# Dropout layers fight overfitting and forces the model to learn multiple \n",
        "# representations of the same data by randomly disabling neurons in the \n",
        "# learning phase.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# We are using a fast version of LSTM which is optimised for GPUs. This layer \n",
        "# looks at the sequence of words in the tweet, along with their word embeddings\n",
        "# and uses both of these to determine to sentiment of a given tweet.\n",
        "model.add(\n",
        "    tf.keras.layers.LSTM(\n",
        "        units=32 # 32 LSTM units in this layer\n",
        "    )\n",
        ")\n",
        "\n",
        "# Add a second dropout layer with the same aim as the first.\n",
        "model.add(\n",
        "    tf.keras.layers.Dropout(\n",
        "        rate=0.25 # Randomly disable 25% of neurons\n",
        "    )\n",
        ")\n",
        "\n",
        "# All LSTM units are connected to a single node in the dense layer. A sigmoid \n",
        "# activation function determines the output from this node - a value \n",
        "# between 0 and 1. Closer to 0 indicates a negative tweet. Closer to 1 \n",
        "# indicates a positive tweet.\n",
        "model.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1, # Single unit\n",
        "        activation='sigmoid' # Sigmoid activation function (output from 0 to 1)\n",
        "    )\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.binary_crossentropy, # loss function\n",
        "    optimizer=tf.keras.optimizers.Adam(), # optimiser function\n",
        "    metrics=['accuracy']) # reporting metric\n",
        "\n",
        "# Display a summary of the models structure\n",
        "model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 450, 32)           320000    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 450, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 32)                8320      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 328,353\n",
            "Trainable params: 328,353\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZoRZl-6UIuN"
      },
      "source": [
        "###**Training LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VCzIkA4IUQKb",
        "outputId": "0caaff46-6224-4fa6-e626-f4ea740206d9"
      },
      "source": [
        "# Train the LSTM on the training data\n",
        "history = model.fit(x_train, y_train, batch_size=256, epochs=5,validation_split=0.2,verbose=1) "
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.6300 - accuracy: 0.6485 - val_loss: 0.6388 - val_accuracy: 0.6765\n",
            "Epoch 2/5\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 0.6058 - accuracy: 0.7191 - val_loss: 0.6119 - val_accuracy: 0.6941\n",
            "Epoch 3/5\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 0.5656 - accuracy: 0.7471 - val_loss: 0.5969 - val_accuracy: 0.6676\n",
            "Epoch 4/5\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 0.5199 - accuracy: 0.7713 - val_loss: 0.5463 - val_accuracy: 0.7412\n",
            "Epoch 5/5\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 0.5010 - accuracy: 0.7897 - val_loss: 0.5643 - val_accuracy: 0.7206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1ZT3bFaUUug"
      },
      "source": [
        "###**Sklearn classification report**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-37CmrwAUU3h",
        "outputId": "261ca581-e538-43e6-9045-c871ce91791c"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Get Model Predictions for test data\n",
        "from sklearn.metrics import classification_report\n",
        "predicted_classes = model.predict_classes(x_test)\n",
        "print(classification_report(y_test, predicted_classes, target_names=[\"Negative\",\"Positive\"]))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.70      0.79      0.74       157\n",
            "    Positive       0.73      0.63      0.68       143\n",
            "\n",
            "    accuracy                           0.71       300\n",
            "   macro avg       0.72      0.71      0.71       300\n",
            "weighted avg       0.72      0.71      0.71       300\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcF8HrWOANqw"
      },
      "source": [
        "###**Answer the following questions**\n",
        "**What are you noticing here? Anything unexpected?** Looking at the performance from the LSTM model, I was expecting to have acceptable results, but turns out that, looking at the precision and recall, the model did a very bad job\n",
        "\n",
        "**How does this model compare to the one built with the IMDB dataset in class?**\n",
        "One of the differences from the model from Class 19 is that, that one has more samples to train (25,000 for training and 25,000 for testing), while this one only had 1,700 for training and 300 records for testing. Also, the data split is different, the one from Class 19 has 50%/50% for training and testing, while this one has 85%/15% for training and testing. And finally, the length from class 19 is 500, while this one is 450. The reason why I think the model from Class 19 performed better is because it had more data to be trained and tested, thus, we got better results compared to this model that used a very small dataset.\n",
        "\n",
        " **Any ideas on how to improve it?** If we don't have the option to get more data for training, the other alternative could be pre-processing the data, that is, removing stop words. Also, increasing the length, and the number of LSTM units in the Layer, as well as the number of batches and modifying the learning rate from Adam Optimizer, could lead to get a better performance, although it would require more GPU resources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ptbrvkw1VIgm"
      },
      "source": [
        "##**EXERCISE 6**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeTFNhRTVOM2"
      },
      "source": [
        "**(30 points)** Use the **train.txt** file from the [PubMed 20K RCT dataset](https://github.com/Franck-Dernoncourt/pubmed-rct/tree/master/PubMed_20k_RCT) fine-tune a BERT transformer (class 9 code). This task is a bit different as the one seen in class, here the source dataset has FIVE different classes: **background, objective, method, result, and conclusion**. Once the BERT model is fine-tuned, classify the: **test.txt** set. Please present the per-class classification report (accuracy, precision, recall, f1-score metrics). Also, present the global metrics - all classes (accuracy, precision, recall, f1-score metrics).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-ODTtmrdBbe"
      },
      "source": [
        "###**Obtaining the training and test files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jcazg3prdKTt"
      },
      "source": [
        "#Downloading the train.txt file\n",
        "!wget https://github.com/Franck-Dernoncourt/pubmed-rct/raw/master/PubMed_20k_RCT/train.txt -O train.txt\n",
        "#Downloading the test.txt file\n",
        "!wget https://github.com/Franck-Dernoncourt/pubmed-rct/raw/master/PubMed_20k_RCT/test.txt -O test.txt\n",
        "clear_output()"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hawmdEyJdBl3",
        "outputId": "62acc187-45f8-406e-9d35-7fc6dc21a9a1"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "#Reading train.txt file\n",
        "#Convert txt file to TSV file\n",
        "with open('train.txt') as infile, open('train.tsv', 'w') as outfile:\n",
        "    for line in infile:\n",
        "        if not line.strip(): continue\n",
        "        if line.startswith('###'): continue\n",
        "        outfile.write(line)\n",
        "\n",
        "#Reading the new TSV file from the training data\n",
        "df_training_data = pd.read_csv('train.tsv', sep='\\t',encoding = 'utf8',lineterminator='\\n',\n",
        "                                 names = ['Class','Text'], low_memory=False, dtype=str)\n",
        "df_training_data['Type'] = \"Training\"\n",
        "\n",
        "#Reading test.txt file\n",
        "\n",
        "#Convert txt file to TSV file\n",
        "with open('test.txt') as infile, open('test.tsv', 'w') as outfile:\n",
        "    for line in infile:\n",
        "        #We remove empty lines and unnecesary lines\n",
        "        if not line.strip(): continue\n",
        "        if line.startswith('###'): continue\n",
        "        outfile.write(line)\n",
        "\n",
        "#Reading the new TSV file from the training data\n",
        "df_val_data = pd.read_csv('test.tsv', sep='\\t',encoding = 'utf8',lineterminator='\\n',\n",
        "                                 names = ['Class','Text'], low_memory=False, dtype=str)\n",
        "df_val_data['Type'] = \"Validation\"\n",
        "\n",
        "#Encoding the Labels\n",
        "possible_labels = df_training_data['Class'].unique()\n",
        "label_dict = {}\n",
        "for index, possible_label in enumerate(possible_labels):\n",
        "    label_dict[possible_label] = index\n",
        "\n",
        "#Inserting the labels with the encoded labels\n",
        "df_training_data['Label'] = df_training_data['Class'].replace(label_dict)\n",
        "df_val_data['Label'] = df_val_data['Class'].replace(label_dict)\n",
        "label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
        "\n",
        "frames = [df_training_data,df_val_data]\n",
        "df_data = pd.concat(frames)\n",
        "\n",
        "print(\"\\033[1mSize of training data:\\033[0m \"+str(len(df_training_data))+\"\\n\")\n",
        "print(\"\\033[1mSize of validation data:\\033[0m \"+str(len(df_val_data))+\"\\n\")\n",
        "print(\"\\033[1m===Summary of splits per class===\\033[0m \\n\")\n",
        "df_data.groupby(['Class','Type']).count()['Text']"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mSize of training data:\u001b[0m 180040\n",
            "\n",
            "\u001b[1mSize of validation data:\u001b[0m 30135\n",
            "\n",
            "\u001b[1m===Summary of splits per class===\u001b[0m \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Class        Type      \n",
              "BACKGROUND   Training      21727\n",
              "             Validation     3621\n",
              "CONCLUSIONS  Training      27168\n",
              "             Validation     4571\n",
              "METHODS      Training      59353\n",
              "             Validation     9897\n",
              "OBJECTIVE    Training      13839\n",
              "             Validation     2333\n",
              "RESULTS      Training      57953\n",
              "             Validation     9713\n",
              "Name: Text, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axmrSWFzb06o"
      },
      "source": [
        "###**Installing HuggingFace and importing modules**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QG_tTm3TVpOx"
      },
      "source": [
        "!pip install transformers\n",
        "clear_output()"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_yCaEZ4qGAK"
      },
      "source": [
        "#Modules required for training BERT models\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import torch\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertForPreTraining\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn7Z0IhScZTs"
      },
      "source": [
        "###**BERT Tokenizer and Encoding Data splits**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUQytPVgcd34"
      },
      "source": [
        "#BERT Tokenizer and encoding Data splits\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "                                          \n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df_training_data.Text.values, \n",
        "    add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=128,\n",
        "    return_tensors='pt', # Return pytorch tensors.\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df_val_data.Text.values, \n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=128,\n",
        "    return_tensors='pt',# Return pytorch tensors.\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df_training_data.Label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df_val_data.Label.values)\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZQTyrHvldC3"
      },
      "source": [
        "###**BERT Pre-trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra6cY_vZldKw"
      },
      "source": [
        "#BERT Pre-trained model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_dict), \n",
        "                                                      output_attentions=False, output_hidden_states=False)\n",
        "#Data Loader\n",
        "batch_size = 12\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)\n",
        "#Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5, \n",
        "                  eps=1e-8)       \n",
        "epochs = 3\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)\n",
        "\n",
        "clear_output()"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt3qBHI6mI4Z"
      },
      "source": [
        "###**Defining performance metrics**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7yrlH45mI-N"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7NAXtQrmOGH"
      },
      "source": [
        "###**Training process**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QtQsNhPqmOK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "377098ad-59d0-474c-b171-6cb7efd75ab2"
      },
      "source": [
        "#Set seed to 12345\n",
        "torch.manual_seed(12345)\n",
        "torch.cuda.manual_seed_all(12345)\n",
        "\n",
        "#To avoid our CUDA's memory being full, we empty the cache first\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cuda:0\"\n",
        "model = model.to(device)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(dataloader_train):\n",
        "\n",
        "        # Progress update every 1000 batches.\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader_train), elapsed))\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()        \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(dataloader_train)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "#Saving fine-tuned BERT model\n",
        "#In order to avoid re-training the code and do this task faster\n",
        "torch.save(model.state_dict(),'finetuned_BERT.model')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:42.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:24.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:07.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:49.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:31.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:14.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:56.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:38.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:20.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:17:02.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:44.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:26.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:08.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:50.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:33.\n",
            "\n",
            "  Average training loss: 0.42\n",
            "  Training epoch took: 0:25:33\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:42.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:24.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:06.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:48.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:30.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:12.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:54.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:36.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:19.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:17:01.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:43.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:25.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:07.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:50.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:32.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epoch took: 0:25:32\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:42.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:24.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:06.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:48.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:30.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:12.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:54.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:35.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:17.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:16:59.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:41.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:22.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:04.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:46.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:27.\n",
            "\n",
            "  Average training loss: 0.25\n",
            "  Training epoch took: 0:25:28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3dEgP2E3nCd"
      },
      "source": [
        "###**Evaluating performance on test.txt dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QfJHf8oX3nKS",
        "outputId": "073ae7ef-1ff2-48fd-e304-9b4150af9bb0"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_val)))\n",
        "print(\"\\n\")\n",
        "\n",
        "#Loading and evaluating the model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('finetuned_BERT.model', map_location=torch.device('cpu')))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in dataloader_validation:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "#Storing the classification report variables\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "true_vals = np.concatenate(true_labels, axis=0)\n",
        "labels_flat = true_vals.flatten()\n",
        "\n",
        "clear_output()\n",
        "print(\"\\033[1mGlobal metrics and per-class metrics (Fine-tuned BERT)\\033[0m \\n\")\n",
        "print(classification_report(labels_flat.tolist(), preds_flat.tolist(), target_names=label_dict_inverse.values()))\n",
        "\n",
        "#For the bonus exercise\n",
        "df_summary_performance = pd.DataFrame(columns=['Model','Precision', 'Recall', 'F1-Score'])\n",
        "\n",
        "model_precision = precision_score(labels_flat.tolist(), preds_flat.tolist(), average='macro')\n",
        "model_recall = recall_score(labels_flat.tolist(), preds_flat.tolist(),average='macro')\n",
        "model_f1 = f1_score(preds_flat.tolist(), labels_flat.tolist(), average='macro')\n",
        "\n",
        "model_bert_metrics = ['BERT', model_precision,model_recall,model_f1]\n",
        "df_summary_performance.loc[len(df_summary_performance), :] = model_bert_metrics"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mGlobal metrics and per-class metrics (Fine-tuned BERT)\u001b[0m \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   OBJECTIVE       0.72      0.60      0.65      2333\n",
            "     METHODS       0.92      0.95      0.94      9897\n",
            "     RESULTS       0.93      0.90      0.91      9713\n",
            " CONCLUSIONS       0.84      0.82      0.83      4571\n",
            "  BACKGROUND       0.68      0.78      0.73      3621\n",
            "\n",
            "    accuracy                           0.87     30135\n",
            "   macro avg       0.82      0.81      0.81     30135\n",
            "weighted avg       0.87      0.87      0.87     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVfIPjuYVpT0"
      },
      "source": [
        "###**Answer the following questions**\n",
        "\n",
        "**Did you model beat the baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it?** Looking at the baseline results and the one obtained from here, I wasn't able to beat them. Some of the possible ways to improve it could be data pre-processing (like removing stop words), increasing the max length, as well as the number of batches and modifying the learning rate from Adam Optimizer. With those adjustments I could probably get a better result compared to the one obtained in this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGb6fObR_2_p"
      },
      "source": [
        "##**BONUS EXERCISE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDsp5pek_5BR"
      },
      "source": [
        "**(50 points)** Solve question 6 but instead for fine-tuning BERT, use: BioBert (20 points) and BlueBERT (20 points) and compare the results of the three approaches in a nice table."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Oo3QbLlAAU7"
      },
      "source": [
        "###**Fine-tuning BioBERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "dc46ec01164b42de9eabe0cba05c7bc9",
            "a2a6d1598e2b4320a395870397064c13",
            "1e2e409fc2df45a992fe2ca14e11f288",
            "3a411cca38ca4c50b58e687958fc4140",
            "772c6067255142f8baa0931afd35bf2b",
            "f0de215f792247cc8f37819484329721",
            "11313b64efc6480ab2f5cf1441bc94ec",
            "20f73d74f24c49e0acad9381a725bebf",
            "a88c142fdf724927bdb7f2d2125129c1",
            "32d90880e518476382813065877febf7",
            "8c21831c41c84db695ce6c83141a348a",
            "83bafd004dd84cc4a287646b81662932",
            "9ba79e58e5d14515a10bdf349bbd245e",
            "3b8c4d52f9114f358860e4343adc1fec",
            "fc1a05961fae4cb0b2739b6cb6fbae4c",
            "9b2e7a499e76450f9af9360b7d99d317",
            "5d1658baa9c643498b076c68d2e9b35e",
            "c547fe6614e1421d96a46bc62bc65f93",
            "76c98c9453b744ddaf7dbb31e38aa3b4",
            "072d15ea99374a5e962138cd22c0f047",
            "64c2dcc67f1b41e19cd1a2f7923006b5",
            "11acbe5f5f4c44b1af7563102cc17e17",
            "2a998a5ccb644c94b75b7eca93be5cf0",
            "d2defb8015674912a76159d65aef8722",
            "5ab319fe128c4afdb2c62ee6df642b21",
            "7bd9df52aaa04d3fba8ebcaf1ef80517",
            "306d7b40ae9f46318da0c79896d10e87",
            "e914c1e231c94829842241db213b461f",
            "2ecaf15877b6486d924dcb2f4d3f87c5",
            "4de593a54fac455baf7ddee563524fd6",
            "4ff475e79ce4403a90e3d40d2eb1a657",
            "2388eda3b265407d849610fd5499694e",
            "52a3320ef4f247e1a98a7d4c1773bbe6",
            "63e4e44e449e4a248e258fe80cb52b5c",
            "abe5d0034a6f42ab95f41f516809e6c2",
            "3404b5a2054442bc9df9204e7bb4a658",
            "b9ae9f80760647fca08b2335bcb8c1e8",
            "db4b5fccd2ef4e71a576888c99bcdcdd",
            "c069ac3e242d4883965e50035ddc61e0",
            "01f907ae318e47a0b6be7d133fb2c341"
          ]
        },
        "id": "WYDvvK_7AAjb",
        "outputId": "0c280d3f-b868-4057-8b69-d150cb69a0a2"
      },
      "source": [
        "#==========BERT Tokenizer and encoding data =====================\n",
        "#BERT Tokenizer and encoding Data splits\n",
        "tokenizer = BertTokenizer.from_pretrained('dmis-lab/biobert-v1.1', do_lower_case=True)\n",
        "                                          \n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df_training_data.Text.values, \n",
        "    add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=128,\n",
        "    return_tensors='pt', # Return pytorch tensors.\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df_val_data.Text.values, \n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=128,\n",
        "    return_tensors='pt',# Return pytorch tensors.\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df_training_data.Label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df_val_data.Label.values)\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "\n",
        "clear_output()\n",
        "#===========BERT PRE-TRAINED MODEL ==============================\n",
        "model = BertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-v1.1\", num_labels=len(label_dict), \n",
        "                                                      output_attentions=False, output_hidden_states=False)\n",
        "\n",
        "#Data Loader\n",
        "batch_size = 12\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)\n",
        "#Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5, \n",
        "                  eps=1e-8)       \n",
        "epochs = 3\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#=====================DEFINING FUNCTIONS ===============================\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "#===================== BERT TRAINING PROCESS ==============================\n",
        "\n",
        "#Set seed to 12345\n",
        "torch.manual_seed(12345)\n",
        "torch.cuda.manual_seed_all(12345)\n",
        "\n",
        "#We run the model in the GPU\n",
        "device = \"cuda:0\"\n",
        "model = model.to(device)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(dataloader_train):\n",
        "\n",
        "        # Progress update every 1000 batches.\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader_train), elapsed))\n",
        "            \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()        \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(dataloader_train)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "#Saving fine-tuned BERT model\n",
        "#In order to avoid re-training the code and do this task faster\n",
        "torch.save(model.state_dict(),'finetuned_BioBERT.model')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:42.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:24.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:05.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:47.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:28.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:10.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:52.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:33.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:15.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:16:56.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:38.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:20.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:01.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:43.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:25.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epoch took: 0:25:25\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:42.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:23.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:05.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:47.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:28.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:10.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:52.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:34.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:15.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:16:57.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:39.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:21.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:02.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:44.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:26.\n",
            "\n",
            "  Average training loss: 0.29\n",
            "  Training epoch took: 0:25:26\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:42.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:23.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:05.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:46.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:28.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:10.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:51.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:33.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:14.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:16:56.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:37.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:19.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:00.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:42.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:23.\n",
            "\n",
            "  Average training loss: 0.22\n",
            "  Training epoch took: 0:25:24\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "dtLLZNrWNPok",
        "outputId": "53fba889-9b1a-4915-d5d0-7214b297d231"
      },
      "source": [
        "#===================== BERT: VALIDATING ON TEST SPLIT ==============================\n",
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_val)))\n",
        "print(\"\\n\")\n",
        "\n",
        "#Loading and evaluating the model\n",
        "model = BertForSequenceClassification.from_pretrained(\"dmis-lab/biobert-v1.1\", num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('finetuned_BioBERT.model', map_location=torch.device('cpu')))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in dataloader_validation:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "#Storing the classification report variables\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "true_vals = np.concatenate(true_labels, axis=0)\n",
        "labels_flat = true_vals.flatten()\n",
        "\n",
        "clear_output()\n",
        "print(\"\\033[1mGlobal metrics and per-class metrics (Fine-tuned BioBERT)\\033[0m \\n\")\n",
        "print(classification_report(labels_flat.tolist(), preds_flat.tolist(), target_names=label_dict_inverse.values()))\n",
        "\n",
        "#Metrics\n",
        "model_precision = precision_score(labels_flat.tolist(), preds_flat.tolist(), average='macro')\n",
        "model_recall = recall_score(labels_flat.tolist(), preds_flat.tolist(),average='macro')\n",
        "model_f1 = f1_score(preds_flat.tolist(), labels_flat.tolist(), average='macro')\n",
        "\n",
        "model_biobert_metrics = ['BioBERT',model_precision,model_recall,model_f1]\n",
        "df_summary_performance.loc[len(df_summary_performance), :] = model_biobert_metrics"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mGlobal metrics and per-class metrics (Fine-tuned BioBERT)\u001b[0m \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   OBJECTIVE       0.71      0.62      0.66      2333\n",
            "     METHODS       0.93      0.95      0.94      9897\n",
            "     RESULTS       0.93      0.92      0.92      9713\n",
            " CONCLUSIONS       0.86      0.84      0.85      4571\n",
            "  BACKGROUND       0.70      0.77      0.74      3621\n",
            "\n",
            "    accuracy                           0.88     30135\n",
            "   macro avg       0.83      0.82      0.82     30135\n",
            "weighted avg       0.88      0.88      0.87     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiFe40guAApD"
      },
      "source": [
        "###**Fine-tuning BlueBERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220,
          "referenced_widgets": [
            "e2f543aab61f46ac89e0da77159a2581",
            "a3de61feb4374689af9ccc213a7eb4db",
            "6cb6a9f18fb14005ade333549b9d2419",
            "554f44c227714a1ca661de337dfbaff3",
            "182a94c66e9b48ca841eb6795a0234c0",
            "d18166b29ee3454f88ec891bb2e3171b",
            "314ec7e922224614957584e3e46ea7bb",
            "371141f377ab48cfb07030b8c63730f5",
            "1936f00b399b44e0853600d40d14f349",
            "7c3d11b6fbf94d0aa8c8edc1535697e0",
            "469b364077e94bce9685e7189b8417ff",
            "6164d356f9cc4c428b738cbd17ac4bb3",
            "40418408d720468e99feb5070b200996",
            "7c307842c959491a9f0cb52b1f04d207",
            "1e2637add551479bbc9d03a56dd2a9ba",
            "4e28e95c3eb54c93bd7f7f5dd5057861"
          ]
        },
        "id": "XYKvsynuAAt2",
        "outputId": "a9313800-54be-43cc-c650-e9bd2db80ad8"
      },
      "source": [
        "#==========BERT Tokenizer and encoding data =====================\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "                                          \n",
        "encoded_data_train = tokenizer.batch_encode_plus(\n",
        "    df_training_data.Text.values, \n",
        "    add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=128,\n",
        "    return_tensors='pt', # Return pytorch tensors.\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "encoded_data_val = tokenizer.batch_encode_plus(\n",
        "    df_val_data.Text.values, \n",
        "    add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "    return_attention_mask=True, \n",
        "    pad_to_max_length=True, \n",
        "    max_length=128,\n",
        "    return_tensors='pt',# Return pytorch tensors.\n",
        "    truncation=True\n",
        ")\n",
        "\n",
        "input_ids_train = encoded_data_train['input_ids']\n",
        "attention_masks_train = encoded_data_train['attention_mask']\n",
        "labels_train = torch.tensor(df_training_data.Label.values)\n",
        "\n",
        "input_ids_val = encoded_data_val['input_ids']\n",
        "attention_masks_val = encoded_data_val['attention_mask']\n",
        "labels_val = torch.tensor(df_val_data.Label.values)\n",
        "\n",
        "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#===========BERT PRE-TRAINED MODEL ==============================\n",
        "model = BertForSequenceClassification.from_pretrained(\"bionlp/bluebert_pubmed_uncased_L-12_H-768_A-12\", num_labels=len(label_dict), \n",
        "                                                      output_attentions=False, output_hidden_states=False)\n",
        "\n",
        "#Data Loader\n",
        "batch_size = 12\n",
        "dataloader_train = DataLoader(dataset_train, \n",
        "                              sampler=RandomSampler(dataset_train), \n",
        "                              batch_size=batch_size)\n",
        "dataloader_validation = DataLoader(dataset_val, \n",
        "                                   sampler=SequentialSampler(dataset_val), \n",
        "                                   batch_size=batch_size)\n",
        "#Optimizer and scheduler\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr=2e-5, \n",
        "                  eps=1e-8)       \n",
        "epochs = 3\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps=0,\n",
        "                                            num_training_steps=len(dataloader_train)*epochs)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "#=====================DEFINING FUNCTIONS ===============================\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "#===================== BERT TRAINING PROCESS ==============================\n",
        "\n",
        "#Set seed to 12345\n",
        "torch.manual_seed(12345)\n",
        "torch.cuda.manual_seed_all(12345)\n",
        "\n",
        "#To avoid our CUDA's memory being full, we empty the cache first\n",
        "torch.cuda.empty_cache()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = \"cuda:0\"\n",
        "model = model.to(device)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(dataloader_train):\n",
        "\n",
        "        # Progress update every 1000 batches.\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(dataloader_train), elapsed))\n",
        "            \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        model.zero_grad()        \n",
        "        result = model(b_input_ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=b_input_mask, \n",
        "                       labels=b_labels)\n",
        "\n",
        "        loss = result.loss\n",
        "        logits = result.logits\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(dataloader_train)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "\n",
        "#Saving fine-tuned BERT model\n",
        "#In order to avoid re-training the code and do this task faster\n",
        "torch.save(model.state_dict(),'finetuned_BlueBERT.model')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:44.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:28.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:12.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:56.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:40.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:23.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:12:06.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:50.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:33.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:17:17.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:19:00.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:43.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:27.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:24:09.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:52.\n",
            "\n",
            "  Average training loss: 0.37\n",
            "  Training epoch took: 0:25:52\n",
            "\n",
            "======== Epoch 2 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:43.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:25.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:08.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:51.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:34.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:16.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:11:59.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:41.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:24.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:17:06.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:49.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:32.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:15.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:23:58.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:41.\n",
            "\n",
            "  Average training loss: 0.28\n",
            "  Training epoch took: 0:25:41\n",
            "\n",
            "======== Epoch 3 / 3 ========\n",
            "Training...\n",
            "  Batch 1,000  of  15,004.    Elapsed: 0:01:43.\n",
            "  Batch 2,000  of  15,004.    Elapsed: 0:03:27.\n",
            "  Batch 3,000  of  15,004.    Elapsed: 0:05:11.\n",
            "  Batch 4,000  of  15,004.    Elapsed: 0:06:54.\n",
            "  Batch 5,000  of  15,004.    Elapsed: 0:08:36.\n",
            "  Batch 6,000  of  15,004.    Elapsed: 0:10:19.\n",
            "  Batch 7,000  of  15,004.    Elapsed: 0:12:02.\n",
            "  Batch 8,000  of  15,004.    Elapsed: 0:13:46.\n",
            "  Batch 9,000  of  15,004.    Elapsed: 0:15:29.\n",
            "  Batch 10,000  of  15,004.    Elapsed: 0:17:11.\n",
            "  Batch 11,000  of  15,004.    Elapsed: 0:18:55.\n",
            "  Batch 12,000  of  15,004.    Elapsed: 0:20:38.\n",
            "  Batch 13,000  of  15,004.    Elapsed: 0:22:22.\n",
            "  Batch 14,000  of  15,004.    Elapsed: 0:24:05.\n",
            "  Batch 15,000  of  15,004.    Elapsed: 0:25:48.\n",
            "\n",
            "  Average training loss: 0.21\n",
            "  Training epoch took: 0:25:49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "16mz9c3gkCvl",
        "outputId": "37488b80-1489-4fb8-acc4-9ef7b53b16ba"
      },
      "source": [
        "#===================== BERT: VALIDATING ON TEST SPLIT ==============================\n",
        "# Prediction on test set\n",
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids_val)))\n",
        "print(\"\\n\")\n",
        "\n",
        "#Loading and evaluating the model\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=len(label_dict), output_attentions=False, output_hidden_states=False)\n",
        "model.to(device)\n",
        "model.load_state_dict(torch.load('finetuned_BlueBERT.model', map_location=torch.device('cpu')))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in dataloader_validation:\n",
        "  # Add batch to GPU\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  \n",
        "  # Unpack the inputs from our dataloader\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  \n",
        "  # Telling the model not to compute or store gradients, saving memory and \n",
        "  # speeding up prediction\n",
        "  with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions.\n",
        "      result = model(b_input_ids, \n",
        "                     token_type_ids=None, \n",
        "                     attention_mask=b_input_mask,\n",
        "                     return_dict=True)\n",
        "\n",
        "  logits = result.logits\n",
        "\n",
        "  # Move logits and labels to CPU\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "\n",
        "#Storing the classification report variables\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "preds_flat = np.argmax(predictions, axis=1).flatten()\n",
        "true_vals = np.concatenate(true_labels, axis=0)\n",
        "labels_flat = true_vals.flatten()\n",
        "\n",
        "clear_output()\n",
        "print(\"\\033[1mGlobal metrics and per-class metrics (Fine-tuned BlueBERT)\\033[0m \\n\")\n",
        "print(classification_report(labels_flat.tolist(), preds_flat.tolist(), target_names=label_dict_inverse.values()))\n",
        "\n",
        "#Metrics\n",
        "model_precision = precision_score(labels_flat.tolist(), preds_flat.tolist(), average='macro')\n",
        "model_recall = recall_score(labels_flat.tolist(), preds_flat.tolist(),average='macro')\n",
        "model_f1 = f1_score(preds_flat.tolist(), labels_flat.tolist(), average='macro')\n",
        "\n",
        "model_bluebert_metrics = ['BlueBERT',model_precision,model_recall,model_f1]\n",
        "df_summary_performance.loc[len(df_summary_performance), :] = model_bluebert_metrics"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mGlobal metrics and per-class metrics (Fine-tuned BlueBERT)\u001b[0m \n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "   OBJECTIVE       0.73      0.60      0.66      2333\n",
            "     METHODS       0.93      0.95      0.94      9897\n",
            "     RESULTS       0.93      0.92      0.92      9713\n",
            " CONCLUSIONS       0.87      0.83      0.85      4571\n",
            "  BACKGROUND       0.70      0.79      0.74      3621\n",
            "\n",
            "    accuracy                           0.88     30135\n",
            "   macro avg       0.83      0.82      0.82     30135\n",
            "weighted avg       0.88      0.88      0.88     30135\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uom4-Y2RnauT"
      },
      "source": [
        "###**Comparing overall performance between BERT, BioBERT and BlueBERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "jh9ztbKVnilD",
        "outputId": "b3a74bb7-2448-4b55-ef93-ecacd2e6074d"
      },
      "source": [
        "df_summary_performance"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BERT</td>\n",
              "      <td>0.818611</td>\n",
              "      <td>0.808089</td>\n",
              "      <td>0.811479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>BioBERT</td>\n",
              "      <td>0.82756</td>\n",
              "      <td>0.819031</td>\n",
              "      <td>0.822237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BlueBERT</td>\n",
              "      <td>0.831964</td>\n",
              "      <td>0.820221</td>\n",
              "      <td>0.824229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Model Precision    Recall  F1-Score\n",
              "0      BERT  0.818611  0.808089  0.811479\n",
              "1   BioBERT   0.82756  0.819031  0.822237\n",
              "2  BlueBERT  0.831964  0.820221  0.824229"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nx8dT9cRABLh"
      },
      "source": [
        "###**Answer the following questions**\n",
        "\n",
        "**Did you model beat the baseline results (https://arxiv.org/pdf/1710.06071.pdf)? What do you think you can do to improve it?** Still I wasn't able to to beat the baseline results even with these fine-tuned BERT model. Besides the options I explained in Exercise 6 to improve the results (removing stop words, increasing max length and number of batches), I think implementing an ensemble approach with these three PRE-trained BERT models, could lead to get a better results in terms of performance."
      ]
    }
  ]
}